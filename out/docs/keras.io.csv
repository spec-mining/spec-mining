KEYWORD,MATCHING SENTENCE,PAGE URL
should,"For most people and most use cases, this is what you should be using.",https://keras.io/api/models/
only,Weights-only saving & loading,https://keras.io/api/models/
note,Note that you may use any loss function as a metric.,https://keras.io/api/metrics/
note,Note that the best way to monitor your metrics during training is via TensorBoard.,https://keras.io/api/metrics/
note,Note that sample weighting is automatically supported for any such metric.,https://keras.io/api/metrics/
should,"The purpose of loss functions is to compute the quantity that a model should seek
to minimize during training.",https://keras.io/api/losses/
note,Note that all losses are available both via a class handle and via a function handle.,https://keras.io/api/losses/
should,"For
    sparse loss functions, such as sparse categorical crossentropy, the shape
    should be (batch_size, d0, .",https://keras.io/api/losses/
note,"(Note ondN-1: all loss
    functions reduce by 1 dimension, usually axis=-1.",https://keras.io/api/losses/
note,Note that this is an important difference between loss functions like keras.,https://keras.io/api/losses/
note,Note that sample weighting is automatically supported for any such loss.,https://keras.io/api/losses/
only,"Loss functions applied to the output of a model aren't the only way to
create losses.",https://keras.io/api/losses/
only,losses always contain only the losses created during the last forward pass.,https://keras.io/api/losses/
should,"When writing a custom training loop, you should retrieve these terms
by hand from model.",https://keras.io/api/losses/
should,"Therefore, these lower-precision dtypes should be used whenever possible on those devices.",https://keras.io/api/mixed_precision/
should,"However, variables storage (as well as certain sensitive computations) should still be in float32
to preserve numerical stability.",https://keras.io/api/mixed_precision/
only,"While mixed precision will run on most hardware, it will only speed up models on recent NVIDIA GPUs and Google TPUs.",https://keras.io/api/mixed_precision/
note,"Note: Only dicts, lists, and tuples of input tensors are supported.",https://keras.io/api/models/model
only,"Note: Only dicts, lists, and tuples of input tensors are supported.",https://keras.io/api/models/model
not support,"Nested
inputs are not supported (e.",https://keras.io/api/models/model
note,"Note that the backbone and activations models are not
created with keras.",https://keras.io/api/models/model
should,"In that case, you should define your
layers in __init__() and you should implement the model's forward pass
in call().",https://keras.io/api/models/model
should,"y_true should have shape (batch_size, d0, .",https://keras.io/api/models/model_training_apis
should,"y_pred should have shape (batch_size, d0, .",https://keras.io/api/models/model_training_apis
should,The loss function should return a float tensor.,https://keras.io/api/models/model_training_apis
note,"Note that if steps_per_execution is set to N,
  Callback.",https://keras.io/api/models/model_training_apis
only,"on_batch_end methods
  will only be called every N batches (i.",https://keras.io/api/models/model_training_apis
not support,Not supported with the PyTorch backend.,https://keras.io/api/models/model_training_apis
should,"Should return a tuple
of either (inputs, targets) or
(inputs, targets, sample_weights).",https://keras.io/api/models/model_training_apis
should,"Should return a tuple
of either (inputs, targets) or
(inputs, targets, sample_weights).",https://keras.io/api/models/model_training_apis
should,"PyDataset instance, y should
  not be specified (since targets will be obtained from x).",https://keras.io/api/models/model_training_apis
note,"Note that in conjunction with initial_epoch,
  epochs is to be understood as ""final epoch"".",https://keras.io/api/models/model_training_apis
note,"Note that the progress bar is not
  particularly useful when logged to a file,
  so verbose=2 is recommended when not running interactively
  (e.",https://keras.io/api/models/model_training_apis
note,"Note
  keras.",https://keras.io/api/models/model_training_apis
not support,"This
  argument is not supported when x is a dataset, generator or
  keras.",https://keras.io/api/models/model_training_apis
note,"Thus, note the fact
  that the validation loss of data provided using
  validation_split or validation_data is not affected by
  regularization layers like noise and dropout.",https://keras.io/api/models/model_training_apis
only,"class_weight: Optional dictionary mapping class indices (integers)
  to a weight (float) value, used for weighting the loss function
  (during training only).",https://keras.io/api/models/model_training_apis
must,"When class_weight is specified
  and targets have a rank of 2 or greater, either y must be
  one-hot encoded, or an explicit final dimension of 1 must
  be included for sparse class labels.",https://keras.io/api/models/model_training_apis
only,"sample_weight: Optional NumPy array of weights for
  the training samples, used for weighting the loss function
  (during training only).",https://keras.io/api/models/model_training_apis
not support,"This argument is not supported when x is a dataset, generator,
  or keras.",https://keras.io/api/models/model_training_apis
note,"Note that sample weighting does not apply to metrics specified
  via the metrics argument in compile().",https://keras.io/api/models/model_training_apis
must,"When passing an infinitely repeating dataset, you
  must specify the steps_per_epoch argument.",https://keras.io/api/models/model_training_apis
only,validation_steps: Only relevant if validation_data is provided.,https://keras.io/api/models/model_training_apis
only,"If validation_steps is
  specified and only part of the dataset will be consumed, the
  evaluation will start from the beginning of the dataset at each
  epoch.",https://keras.io/api/models/model_training_apis
only,validation_freq: Only relevant if validation data is provided.,https://keras.io/api/models/model_training_apis
only,"PyDataset to fit(),
    which will in fact yield not only features (x)
    but optionally targets (y) and sample weights (sample_weight).",https://keras.io/api/models/model_training_apis
should,"The iterator should return a tuple
    of length 1, 2, or 3, where the optional second and third elements
    will be used for y and sample_weight respectively.",https://keras.io/api/models/model_training_apis
should,"When
    yielding dicts, they should still adhere to the top-level tuple
    structure,
    e.",https://keras.io/api/models/model_training_apis
should,"Should return a tuple
    of either (inputs, targets) or
    (inputs, targets, sample_weights).",https://keras.io/api/models/model_training_apis
should,"Should return a tuple
    of either (inputs, targets) or
    (inputs, targets, sample_weights).",https://keras.io/api/models/model_training_apis
should,"PyDataset
  instance, y should not be specified
  (since targets will be obtained from the iterator/dataset).",https://keras.io/api/models/model_training_apis
note,"Note that the progress bar is not
  particularly useful when logged to a file, so verbose=2 is
  recommended when not running interactively
  (e.",https://keras.io/api/models/model_training_apis
not support,"This argument is not supported when
  x is a dataset, instead pass sample weights as the third
  element of x.",https://keras.io/api/models/model_training_apis
note,"Note: See this FAQ entry
for more details about the difference between Model methods
predict() and __call__().",https://keras.io/api/models/model_training_apis
note,"Note that the progress bar
  is not particularly useful when logged to a file,
  so verbose=2 is recommended when not running interactively
  (e.",https://keras.io/api/models/model_training_apis
must,Must be array-like.,https://keras.io/api/models/model_training_apis
must,Must be array-like.,https://keras.io/api/models/model_training_apis
must,"When class_weight is specified
  and targets have a rank of 2 or greater, either y must
  be one-hot encoded, or an explicit final dimension of 1
  must be included for sparse class labels.",https://keras.io/api/models/model_training_apis
must,Must be array-like.,https://keras.io/api/models/model_training_apis
must,Must be array-like.,https://keras.io/api/models/model_training_apis
must,It must be array-like.,https://keras.io/api/models/model_training_apis
only,Weights-only saving & loading,https://keras.io/api/models/model_saving_apis/
should,"Nested layers should be instantiated in the
__init__() method or build() method.",https://keras.io/api/layers/base_layer
should,"trainable: Boolean, whether the layer's variables should be trainable.",https://keras.io/api/layers/base_layer
should,"non_trainable_weights: List of variables that should not be
  included in backprop.",https://keras.io/api/layers/base_layer
should,"trainable: Whether the layer should be trained (boolean), i.",https://keras.io/api/layers/base_layer
should,"whether its potentially-trainable weights should be returned
  as part of layer.",https://keras.io/api/layers/base_layer
should,"These are the weights that should not be updated by the optimizer during
training.",https://keras.io/api/layers/base_layer
must,Must be fully-defined (no None entries).,https://keras.io/api/layers/base_layer
should,"trainable: Boolean, whether the variable should
  be trainable via backprop or whether its
  updates are managed manually.",https://keras.io/api/layers/base_layer
should,"Settable boolean, whether this layer should be trainable or not.",https://keras.io/api/layers/base_layer
note,Notes:,https://keras.io/api/layers/activations
should,"You can also use a callable as an activation
(in this case it should take a tensor and return a tensor of the same shape and dtype):",https://keras.io/api/layers/activations
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/layers/initializers
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/layers/initializers
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/layers/initializers
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/layers/initializers
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/layers/initializers
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/layers/initializers
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/layers/initializers
only,Only scalar values are allowed.,https://keras.io/api/layers/initializers
must,"The constant value provided must be convertible to the dtype requested
when calling the initializer.",https://keras.io/api/layers/initializers
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/layers/initializers
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/layers/initializers
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/layers/initializers
only,Only usable for generating 2D matrices.,https://keras.io/api/layers/initializers
should,"stddev argument in RandomNormal),
you should implement it as a subclass of keras.",https://keras.io/api/layers/initializers
should,"Initializers should implement a __call__ method with the following
signature:",https://keras.io/api/layers/initializers
note,"Note that we don't have to implement from_config in the example above since
the constructor arguments of the class the keys in the config returned by
get_config are the same.",https://keras.io/api/layers/initializers
note,A note on serialization and deserialization:,https://keras.io/api/layers/regularizers
must,"If using this
functionality, you must make sure any python process running your model has
also defined and registered your custom regularizer.",https://keras.io/api/layers/regularizers
should,"l1 and l2 arguments in l1_l2),
you should implement it as a subclass of keras.",https://keras.io/api/layers/regularizers
should,"Users who subclass this
class should override the __call__() method, which takes a single
weight parameter and return a projected version of that parameter
(e.",https://keras.io/api/layers/constraints
note,"Note that we don't have to implement from_config
in the example above since the constructor arguments of the class
the keys in the config returned by get_config are the same.",https://keras.io/api/layers/constraints
should,You should pack all your callbacks into a single callbacks.,https://keras.io/api/callbacks/base_callback
only,"Whether to only keep the model that has achieved the ""best performance"" so
  far, or whether to save the model at the end of every epoch regardless of
  performance.",https://keras.io/api/callbacks/model_checkpoint
should,"Definition of ""best""; which quantity to monitor and whether it should be
  maximized or minimized.",https://keras.io/api/callbacks/model_checkpoint
should,The frequency it should save at.,https://keras.io/api/callbacks/model_checkpoint
only,"Whether only weights are saved, or the whole model is saved.",https://keras.io/api/callbacks/model_checkpoint
only,"h5"" when
  save_weights_only=True or should end with "".",https://keras.io/api/callbacks/model_checkpoint
should,"h5"" when
  save_weights_only=True or should end with "".",https://keras.io/api/callbacks/model_checkpoint
should,"The directory of the filepath
  should not be reused by any other callbacks to avoid conflicts.",https://keras.io/api/callbacks/model_checkpoint
note,"Note:
Prefix the name with ""val_"" to monitor validation metrics.",https://keras.io/api/callbacks/model_checkpoint
should,"Metric objects, monitor should be set to
    metric.",https://keras.io/api/callbacks/model_checkpoint
should,"Metric objects, monitor should be set to
    metric.",https://keras.io/api/callbacks/model_checkpoint
only,"save_best_only: if save_best_only=True, it only saves when the model
  is considered the ""best"" and the latest best model according to the
  quantity monitored will not be overwritten.",https://keras.io/api/callbacks/model_checkpoint
only,"If save_best_only=True, the
  decision to overwrite the current save file is made based on either
  the maximization or the minimization of the monitored quantity.",https://keras.io/api/callbacks/model_checkpoint
should,"For val_acc, this should be ""max"", for val_loss this should be
  ""min"", etc.",https://keras.io/api/callbacks/model_checkpoint
only,"save_weights_only: if True, then only the model's weights will be
  saved (model.",https://keras.io/api/callbacks/model_checkpoint
note,"Note that if the saving isn't aligned to
  epochs, the monitored metric may potentially be less reliable (it
  could reflect as little as 1 batch, since the metrics get reset
  every epoch).",https://keras.io/api/callbacks/model_checkpoint
only,Only applies if save_best_value=True.,https://keras.io/api/callbacks/model_checkpoint
only,"Only
  overwrites the model weights already saved if the performance of
  current model is better than this value.",https://keras.io/api/callbacks/model_checkpoint
note,Note that the user is responsible to bring jobs back after the interruption.,https://keras.io/api/callbacks/backup_and_restore
only,"Set save_freq=False only if using
  preemption checkpointing (i.",https://keras.io/api/callbacks/backup_and_restore
should,"If you have installed TensorFlow with pip, you should be able
to launch TensorBoard from the command line:",https://keras.io/api/callbacks/tensorboard
should,This directory should not be reused by any other callbacks.,https://keras.io/api/callbacks/tensorboard
must,"Validation data (or split) must be
  specified for histogram visualizations.",https://keras.io/api/callbacks/tensorboard
not support,"write_graph:  (Not supported at this time)
  Whether to visualize the graph in TensorBoard.",https://keras.io/api/callbacks/tensorboard
note,"Note that the log file can become quite large
  when write_graph is set to True.",https://keras.io/api/callbacks/tensorboard
note,"Note however that writing too frequently to TensorBoard can slow
  down your training, especially when used with distribution
  strategies as it will incur additional synchronization overhead.",https://keras.io/api/callbacks/tensorboard
not support,"profile_batch: (Not supported at this time)
  Profile the batch(es) to sample compute characteristics.",https://keras.io/api/callbacks/tensorboard
must,profile_batch must be a non-negative integer or a tuple of integers.,https://keras.io/api/callbacks/tensorboard
only,"Threshold for measuring the new optimum, to only focus
  on significant changes.",https://keras.io/api/callbacks/reduce_lr_on_plateau
only,"The field is used only if the payload is sent within a form
  (i.",https://keras.io/api/callbacks/remote_monitor
should,"send_as_json: Boolean; whether the request should be
  sent as ""application/json"".",https://keras.io/api/callbacks/remote_monitor
should,"Whether the progress bar should
  count samples seen or steps (batches) seen.",https://keras.io/api/callbacks/progbar_logger
note,Note that the weights are swapped in-place in order to save memory.,https://keras.io/api/callbacks/swap_ema_weights
must,"When axis is specified, x1 and x2 must have compatible shapes.",https://keras.io/api/ops/numpy/
must,"If step is
  specified as a position argument, start must also be given.",https://keras.io/api/ops/numpy/
note,"(Note the role reversal: the ""y-coordinate""
is the first function parameter, the ""x-coordinate"" is the second.",https://keras.io/api/ops/numpy/
note,Note the order of the parameters.,https://keras.io/api/ops/numpy/
must,"The weights array can either be 1-D (in which
  case its length must be the size of a along the given axis) or of
  the same shape as x.",https://keras.io/api/ops/numpy/
must,The only constraint on weights is that sum(weights) must not be 0.,https://keras.io/api/ops/numpy/
only,The only constraint on weights is that sum(weights) must not be 0.,https://keras.io/api/ops/numpy/
must,"It must be of dimension 1, and it must only contain non-negative
  integer(s).",https://keras.io/api/ops/numpy/
only,"It must be of dimension 1, and it must only contain non-negative
  integer(s).",https://keras.io/api/ops/numpy/
must,It must have the same length as x.,https://keras.io/api/ops/numpy/
note,"Note:
    Torch backend does not support two dimensional vectors, or the
    arguments axisa, axisb and axisc.",https://keras.io/api/ops/numpy/
not support,"Note:
    Torch backend does not support two dimensional vectors, or the
    arguments axisa, axisb and axisc.",https://keras.io/api/ops/numpy/
note,"Note:
    Torch backend does not accept 0-D tensors as arguments.",https://keras.io/api/ops/numpy/
note,Note that the step size changes when endpoint is False.,https://keras.io/api/ops/numpy/
must,"Must be
  non-negative.",https://keras.io/api/ops/numpy/
only,"Relevant only if
  start or stop are array-like.",https://keras.io/api/ops/numpy/
note,"Note:
    Torch backend does not support axis argument.",https://keras.io/api/ops/numpy/
not support,"Note:
    Torch backend does not support axis argument.",https://keras.io/api/ops/numpy/
only,"Relevant only
  if start or stop are array-like.",https://keras.io/api/ops/numpy/
note,"Note:
    Torch backend does not support axis argument.",https://keras.io/api/ops/numpy/
not support,"Note:
    Torch backend does not support axis argument.",https://keras.io/api/ops/numpy/
should,x: Tensor whose axes should be reordered.,https://keras.io/api/ops/numpy/
must,These must be unique.,https://keras.io/api/ops/numpy/
must,These must also be unique.,https://keras.io/api/ops/numpy/
note,ord: Order of the norm (see table under Notes).,https://keras.io/api/ops/numpy/
note,"Note:
    For values of ord < 1, the result is, strictly speaking, not a
    mathematical 'norm', but it may still be useful for various numerical
    purposes.",https://keras.io/api/ops/numpy/
not support,"inf: min(sum(abs(x), axis=1))
        - ord=0: not supported
        - ord=1: max(sum(abs(x), axis=0))
        - ord=-1: min(sum(abs(x), axis=0))
        - ord=2: 2-norm (largest sing.",https://keras.io/api/ops/numpy/
not support,"value)
        - ord=-2: smallest singular value
        - other: not supported
    - For vectors:
        - ord=None: 2-norm
        - ord=""fro"": not supported
        - ord=nuc: not supported
        - ord=np.",https://keras.io/api/ops/numpy/
note,"Note:
    Torch backend only supports modes ""constant"", ""reflect"",
    ""symmetric"" and ""circular"".",https://keras.io/api/ops/numpy/
only,"Note:
    Torch backend only supports modes ""constant"", ""reflect"",
    ""symmetric"" and ""circular"".",https://keras.io/api/ops/numpy/
only,"Only Torch backend supports ""circular"" mode.",https://keras.io/api/ops/numpy/
note,"Note:
    Tensorflow backend only supports modes ""constant"", ""reflect""
    and ""symmetric"".",https://keras.io/api/ops/numpy/
only,"Note:
    Tensorflow backend only supports modes ""constant"", ""reflect""
    and ""symmetric"".",https://keras.io/api/ops/numpy/
must,Values must be between 0 and 1 inclusive.,https://keras.io/api/ops/numpy/
should,newshape: The new shape should be compatible with the original shape.,https://keras.io/api/ops/numpy/
note,"Note:
    A split does not have to result in equal division when using
    Torch backend.",https://keras.io/api/ops/numpy/
must,"The sizes of the corresponding
      axes must match.",https://keras.io/api/ops/numpy/
must,"Both sequences must be of the
      same length.",https://keras.io/api/ops/numpy/
only,"Pooling happens over the spatial
  dimensions only.",https://keras.io/api/ops/nn/
should,"axis: Integer, the axis that should be normalized.",https://keras.io/api/ops/nn/
only,"The binary cross-entropy loss is commonly used in binary
classification tasks where each input sample belongs to one
of the two classes.",https://keras.io/api/ops/nn/
should,Its shape should match the shape of the output tensor.,https://keras.io/api/ops/nn/
should,"Its shape should match the shape of the
  target tensor.",https://keras.io/api/ops/nn/
only,"The categorical cross-entropy loss is commonly used in multi-class
classification tasks where each input sample can belong to one of
multiple classes.",https://keras.io/api/ops/nn/
should,"Its shape should match the shape of the output tensor
  except for the last dimension.",https://keras.io/api/ops/nn/
should,"Its shape should match the shape of the target
  tensor except for the last dimension.",https://keras.io/api/ops/nn/
should,"num_input_channels should match the number of channels in
  inputs.",https://keras.io/api/ops/nn/
should,"kernel has shape
  [kernel_spatial_shape, num_output_channels, num_input_channels],
  num_input_channels should match the number of channels in
  inputs.",https://keras.io/api/ops/nn/
must,"The amount of output padding
  along a given dimension must be lower than the stride along that
  same dimension.",https://keras.io/api/ops/nn/
should,"kernel has shape
  [kernel_spatial_shape, num_input_channels, num_channels_multiplier],
  num_input_channels should match the number of channels in
  inputs.",https://keras.io/api/ops/nn/
only,"Pooling happens over the spatial
  dimensions only.",https://keras.io/api/ops/nn/
only,synchronized: Only applicable with the TensorFlow backend.,https://keras.io/api/ops/nn/
should,"axis: (optional) Axis along which the multi-hot encoding should be
  added.",https://keras.io/api/ops/nn/
should,"The shape can be
  arbitrary, but the dtype should be integer.",https://keras.io/api/ops/nn/
should,"depthwise_kernel has shape
  [kernel_spatial_shape, num_input_channels, num_channels_multiplier],
  num_input_channels should match the number of channels in
  inputs.",https://keras.io/api/ops/nn/
should,"Its shape should match the shape of the output
  tensor except for the last dimension.",https://keras.io/api/ops/nn/
should,"Its shape should match the shape of the target tensor except
  for the last dimension.",https://keras.io/api/ops/nn/
note,ord: Order of the norm (see table under Notes).,https://keras.io/api/ops/linalg/
note,"Note:
    For values of ord < 1, the result is, strictly speaking, not a
    mathematical 'norm', but it may still be useful for various numerical
    purposes.",https://keras.io/api/ops/linalg/
not support,"inf: min(sum(abs(x), axis=1))
        - ord=0: not supported
        - ord=1: max(sum(abs(x), axis=0))
        - ord=-1: min(sum(abs(x), axis=0))
        - ord=2: 2-norm (largest sing.",https://keras.io/api/ops/linalg/
not support,"value)
        - ord=-2: smallest singular value
        - other: not supported
    - For vectors:
        - ord=None: 2-norm
        - ord=""fro"": not supported
        - ord=nuc: not supported
        - ord=np.",https://keras.io/api/ops/linalg/
only,"The default value of None means that
  sparse tensors are kept only if the backend supports them.",https://keras.io/api/ops/core/
must,"Must take two
  arguments: the loop variable and the loop state.",https://keras.io/api/ops/core/
should,"The loop state
  should be updated and returned by this function.",https://keras.io/api/ops/core/
note,"Note: This checks for backend specific tensors so passing a TensorFlow
tensor would return False if your backend is PyTorch or JAX.",https://keras.io/api/ops/core/
must,"N is the number of indices to update, must be
  equal to the first dimension of updates.",https://keras.io/api/ops/core/
note,"Note: On the TensorFlow backend, when x is a tf.",https://keras.io/api/ops/core/
must,", Dn),
start_indices must be a list/tuple of n integers, specifying the starting
indices.",https://keras.io/api/ops/core/
must,"updates must have the same rank as inputs, and the size of each
dim must not exceed Di - start_indices[i].",https://keras.io/api/ops/core/
must,updates must have the same rank as inputs.,https://keras.io/api/ops/core/
must,Must accept a loop_vars like structure as an argument.,https://keras.io/api/ops/core/
must,"Must accept a
  loop_vars like structure as an argument, and return update value
  with the same structure.",https://keras.io/api/ops/core/
must,Must be 3D or 4D.,https://keras.io/api/ops/image/
note,"Note that
  gradients are not backpropagated into transformation parameters.",https://keras.io/api/ops/image/
note,"Note that c0 and c1 are only effective when using TensorFlow
  backend and will be considered as 0 when using other backends.",https://keras.io/api/ops/image/
only,"Note that c0 and c1 are only effective when using TensorFlow
  backend and will be considered as 0 when using other backends.",https://keras.io/api/ops/image/
must,Must be 3D or 4D.,https://keras.io/api/ops/image/
must,"For value other than 1,
  strides must be 1.",https://keras.io/api/ops/image/
note,"Note that interpolation near boundaries differs from the scipy function,
because we fixed an outstanding bug
scipy/issues/2640.",https://keras.io/api/ops/image/
must,"The order must be 0 or
  1.",https://keras.io/api/ops/image/
must,Must be 3D or 4D.,https://keras.io/api/ops/image/
should,"Both
  tensors in the tuple should be of floating type.",https://keras.io/api/ops/fft/
should,"Both
  tensors in the tuple should be of floating type.",https://keras.io/api/ops/fft/
only,"Since the Discrete Fourier Transform of a real-valued signal is
Hermitian-symmetric, RFFT only returns the fft_length / 2 + 1 unique
components of the FFT: the zero-frequency term, followed by the
fft_length / 2 positive-frequency terms.",https://keras.io/api/ops/fft/
must,"If window
  is a tensor, it will be used directly as the window and its length
  must be sequence_length.",https://keras.io/api/ops/fft/
should,"If the
FFT length used to compute is odd, it should be provided since it cannot
be inferred properly.",https://keras.io/api/ops/fft/
should,"Both
  tensors in the tuple should be of floating type.",https://keras.io/api/ops/fft/
should,"To reconstruct an original waveform, the parameters should be the same in
stft.",https://keras.io/api/ops/fft/
should,"Both
  tensors in the tuple should be of floating type.",https://keras.io/api/ops/fft/
must,"If window
  is a tensor, it will be used directly as the window and its length
  must be sequence_length.",https://keras.io/api/ops/fft/
only,Only used if use_ema=True.,https://keras.io/api/optimizers/sgd
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/sgd
only,Only used if use_ema=True.,https://keras.io/api/optimizers/rmsprop
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/rmsprop
only,Only used if use_ema=True.,https://keras.io/api/optimizers/adam
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/adam
only,Only used if use_ema=True.,https://keras.io/api/optimizers/adamw
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/adamw
note,"Note that Adadelta
  tends to benefit from higher initial learning rate values compared
  to other optimizers.",https://keras.io/api/optimizers/adadelta
only,Only used if use_ema=True.,https://keras.io/api/optimizers/adadelta
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/adadelta
note,"Note that Adagrad
  tends to benefit from higher initial learning rate values compared
  to other optimizers.",https://keras.io/api/optimizers/adagrad
must,Must be non-negative.,https://keras.io/api/optimizers/adagrad
only,Only used if use_ema=True.,https://keras.io/api/optimizers/adagrad
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/adagrad
only,Only used if use_ema=True.,https://keras.io/api/optimizers/adamax
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/adamax
only,"Adafactor is commonly used in NLP tasks, and has the advantage
of taking less memory because it only saves partial information of previous
gradients.",https://keras.io/api/optimizers/adafactor
only,Only used if use_ema=True.,https://keras.io/api/optimizers/adafactor
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/adafactor
only,Only used if use_ema=True.,https://keras.io/api/optimizers/Nadam
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/Nadam
must,"learning_rate_power: A float value, must be less or equal to zero.",https://keras.io/api/optimizers/ftrl
only,"Only
  zero or positive values are allowed.",https://keras.io/api/optimizers/ftrl
must,"l1_regularization_strength: A float value, must be greater than or equal
  to zero.",https://keras.io/api/optimizers/ftrl
must,"l2_regularization_strength: A float value, must be greater than or equal
  to zero.",https://keras.io/api/optimizers/ftrl
must,"l2_shrinkage_regularization_strength: A float value, must be greater
  than or equal to zero.",https://keras.io/api/optimizers/ftrl
only,"When input is sparse shrinkage will only happen
  on the active weights.",https://keras.io/api/optimizers/ftrl
only,Only used if use_ema=True.,https://keras.io/api/optimizers/ftrl
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/ftrl
only,"This make
Lion more memory-efficient as it only keeps track of the momentum.",https://keras.io/api/optimizers/lion
should,"The weight decay for Lion
should be in turn 3-10x larger than that for AdamW to maintain a
similar strength (lr * wd).",https://keras.io/api/optimizers/lion
only,Only used if use_ema=True.,https://keras.io/api/optimizers/lion
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/lion
only,Only used if use_ema=True.,https://keras.io/api/optimizers/loss_scale_optimizer
only,"Only used if
  use_ema=True.",https://keras.io/api/optimizers/loss_scale_optimizer
should,"__init__(): All state variables should be created in this method by
  calling self.",https://keras.io/api/metrics/base_metric
should,"y_pred and y_true should be passed in as vectors of probabilities,
rather than as labels.",https://keras.io/api/metrics/accuracy_metrics
only,"This is the crossentropy metric class to be used when there are only two
label classes (0 and 1).",https://keras.io/api/metrics/probabilistic_metrics
should,"There should be num_classes floating point values per feature for y_pred
and a single floating point value per feature for y_true.",https://keras.io/api/metrics/probabilistic_metrics
should,"Should be one of
  None (no aggregation), ""uniform_average"",
  ""variance_weighted_average"".",https://keras.io/api/metrics/regression_metrics
should,"For a best approximation of the real AUC, predictions should be
distributed approximately uniformly in the range [0, 1] (if
from_logits=False).",https://keras.io/api/metrics/classification_metrics
must,Values must be > 1.,https://keras.io/api/metrics/classification_metrics
should,"Values should be in [0, 1].",https://keras.io/api/metrics/classification_metrics
should,"multi_label: boolean indicating whether multilabel data should be
  treated as such, wherein AUC is computed separately for each label
  and then averaged across labels, or (when False) if the data
  should be flattened into a single label before AUC computation.",https://keras.io/api/metrics/classification_metrics
should,"Should
  be set to False for multi-class data.",https://keras.io/api/metrics/classification_metrics
note,"Note that this is unlike
  class_weights in that class_weights weights the example
  depending on the value of its label, whereas label_weights depends
  only on the index of that label before flattening; therefore
  label_weights should not be used for multi-class data.",https://keras.io/api/metrics/classification_metrics
only,"Note that this is unlike
  class_weights in that class_weights weights the example
  depending on the value of its label, whereas label_weights depends
  only on the index of that label before flattening; therefore
  label_weights should not be used for multi-class data.",https://keras.io/api/metrics/classification_metrics
should,"Note that this is unlike
  class_weights in that class_weights weights the example
  depending on the value of its label, whereas label_weights depends
  only on the index of that label before flattening; therefore
  label_weights should not be used for multi-class data.",https://keras.io/api/metrics/classification_metrics
should,"As a rule of thumb,
when using a keras loss, the from_logits constructor argument of the
loss should match the AUC from_logits constructor argument.",https://keras.io/api/metrics/classification_metrics
only,"If class_id is specified, we calculate precision by considering only the
entries in the batch for which class_id is above the threshold and/or in
the top-k highest predictions, and computing the fraction of them for which
class_id is indeed a correct label.",https://keras.io/api/metrics/classification_metrics
should,"no sigmoid applied
  to predictions), thresholds should be set to 0.",https://keras.io/api/metrics/classification_metrics
must,"This must be in the half-open interval [0, num_classes), where
  num_classes is the last dimension of predictions.",https://keras.io/api/metrics/classification_metrics
only,"If class_id is specified, we calculate recall by considering only the
entries in the batch for which class_id is in the label, and computing the
fraction of them for which class_id is above the threshold and/or in the
top-k predictions.",https://keras.io/api/metrics/classification_metrics
should,"no sigmoid
  applied to predictions), thresholds should be set to 0.",https://keras.io/api/metrics/classification_metrics
must,"This must be in the half-open interval [0, num_classes), where
  num_classes is the last dimension of predictions.",https://keras.io/api/metrics/classification_metrics
should,"no
  sigmoid applied to predictions), thresholds should be set to 0.",https://keras.io/api/metrics/classification_metrics
should,"no
  sigmoid applied to predictions), thresholds should be set to 0.",https://keras.io/api/metrics/classification_metrics
should,"no
  sigmoid applied to predictions), thresholds should be set to 0.",https://keras.io/api/metrics/classification_metrics
should,"no
  sigmoid applied to predictions), thresholds should be set to 0.",https://keras.io/api/metrics/classification_metrics
only,"If class_id is specified, we calculate precision by considering only the
entries in the batch for which class_id is above the threshold
predictions, and computing the fraction of them for which class_id is
indeed a correct label.",https://keras.io/api/metrics/classification_metrics
must,"This must be in the half-open interval [0, num_classes), where
  num_classes is the last dimension of predictions.",https://keras.io/api/metrics/classification_metrics
only,"If class_id is specified, we calculate precision by considering only the
entries in the batch for which class_id is above the threshold
predictions, and computing the fraction of them for which class_id is
indeed a correct label.",https://keras.io/api/metrics/classification_metrics
must,"This must be in the half-open interval [0, num_classes), where
  num_classes is the last dimension of predictions.",https://keras.io/api/metrics/classification_metrics
only,"If class_id is specified, we calculate precision by considering only the
entries in the batch for which class_id is above the threshold
predictions, and computing the fraction of them for which class_id is
indeed a correct label.",https://keras.io/api/metrics/classification_metrics
must,"This must be in the half-open interval [0, num_classes), where
  num_classes is the last dimension of predictions.",https://keras.io/api/metrics/classification_metrics
only,"If class_id is specified, we calculate precision by considering only the
entries in the batch for which class_id is above the threshold
predictions, and computing the fraction of them for which class_id is
indeed a correct label.",https://keras.io/api/metrics/classification_metrics
must,"This must be in the half-open interval [0, num_classes), where
  num_classes is the last dimension of predictions.",https://keras.io/api/metrics/classification_metrics
note,"Note, this class first computes IoUs for all individual classes, then
returns the mean of IoUs for the classes that are specified by
target_class_ids.",https://keras.io/api/metrics/segmentation_metrics
only,"If target_class_ids has only one id value, the IoU of
that specific class is returned.",https://keras.io/api/metrics/segmentation_metrics
should,"To compute IoU for a specific class, a list
  (or tuple) of a single id value should be provided.",https://keras.io/api/metrics/segmentation_metrics
only,"This is useful, for example, in segmentation
  problems featuring a ""void"" class (commonly -1 or 255) in
  segmentation maps.",https://keras.io/api/metrics/segmentation_metrics
note,"Note: with threshold=0, this metric has the same behavior as IoU.",https://keras.io/api/metrics/segmentation_metrics
should,"This class can be used to compute IoU for multi-class classification tasks
where the labels are one-hot encoded (the last axis should have one
dimension per class).",https://keras.io/api/metrics/segmentation_metrics
note,"Note that the predictions should also have the same
shape.",https://keras.io/api/metrics/segmentation_metrics
should,"Note that the predictions should also have the same
shape.",https://keras.io/api/metrics/segmentation_metrics
note,"Note, if there is only one channel in the labels and predictions, this class
is the same as class IoU.",https://keras.io/api/metrics/segmentation_metrics
only,"Note, if there is only one channel in the labels and predictions, this class
is the same as class IoU.",https://keras.io/api/metrics/segmentation_metrics
should,"To compute IoU for a specific class, a list
  (or tuple) of a single id value should be provided.",https://keras.io/api/metrics/segmentation_metrics
only,"This is useful, for example, in segmentation
  problems featuring a ""void"" class (commonly -1 or 255) in
  segmentation maps.",https://keras.io/api/metrics/segmentation_metrics
should,"This class can be used to compute the mean IoU for multi-class
classification tasks where the labels are one-hot encoded (the last axis
should have one dimension per class).",https://keras.io/api/metrics/segmentation_metrics
note,"Note that the predictions should also
have the same shape.",https://keras.io/api/metrics/segmentation_metrics
should,"Note that the predictions should also
have the same shape.",https://keras.io/api/metrics/segmentation_metrics
note,"Note, if there is only one channel in the labels and predictions, this class
is the same as class MeanIoU.",https://keras.io/api/metrics/segmentation_metrics
only,"Note, if there is only one channel in the labels and predictions, this class
is the same as class MeanIoU.",https://keras.io/api/metrics/segmentation_metrics
only,"This is useful, for example, in segmentation
  problems featuring a ""void"" class (commonly -1 or 255) in
  segmentation maps.",https://keras.io/api/metrics/segmentation_metrics
note,"Note that this class first computes IoUs for all individual classes, then
returns the mean of these values.",https://keras.io/api/metrics/segmentation_metrics
must,"This value must be provided, since a confusion matrix of dimension =
  [num_classes, num_classes] will be allocated.",https://keras.io/api/metrics/segmentation_metrics
only,"This is useful, for example, in segmentation
  problems featuring a ""void"" class (commonly -1 or 255) in
  segmentation maps.",https://keras.io/api/metrics/segmentation_metrics
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/probabilistic_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/probabilistic_losses
should,"There should be num_classes floating
point values per feature, i.",https://keras.io/api/losses/probabilistic_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/probabilistic_losses
must,"If alpha is a list, it must have the same length as the number
of classes.",https://keras.io/api/losses/probabilistic_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/probabilistic_losses
should,"There should be # classes floating point
values per feature for y_pred and a single floating point value per
feature for y_true.",https://keras.io/api/losses/probabilistic_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/probabilistic_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/probabilistic_losses
only,"This is useful, for example, in segmentation
  problems featuring a ""void"" class (commonly -1 or 255) in
  segmentation maps.",https://keras.io/api/losses/probabilistic_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/probabilistic_losses
should,"0 always represents
  the blank/mask index and should not be used for classes.",https://keras.io/api/losses/probabilistic_losses
should,They should not be normalized via softmax.,https://keras.io/api/losses/probabilistic_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/regression_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/regression_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/regression_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/regression_losses
note,Note that it is a number between -1 and 1.,https://keras.io/api/losses/regression_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/regression_losses
note,Note that y_pred and y_true cannot be less or equal to 0.,https://keras.io/api/losses/regression_losses
note,Note that it is a number between -1 and 1.,https://keras.io/api/losses/regression_losses
note,"Note that log(cosh(x)) is approximately equal to (x ** 2) / 2 for small
x and to abs(x) - log(2) for large x.",https://keras.io/api/losses/regression_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/hinge_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/hinge_losses
should,"In almost all cases
  this should be ""sum_over_batch_size"".",https://keras.io/api/losses/hinge_losses
should,"If labels is ""inferred"", it should contain
  subdirectories, each containing images for a class.",https://keras.io/api/data_loading/image
should,"Labels should be sorted
  according to the alphanumeric order of the image file paths
  (obtained via os.",https://keras.io/api/data_loading/image
only,"""binary"" means that the labels (there can be only 2)
    are encoded as float32 scalars with values 0 or 1
    (e.",https://keras.io/api/data_loading/image
only,"""binary"" means that the labels (there can be only 2)
    are encoded as float32 scalars with values 0 or 1
    (e.",https://keras.io/api/data_loading/image
only,"class_names: Only valid if labels is ""inferred"".",https://keras.io/api/data_loading/image
must,"This is the explicit list of class names
  (must match names of subdirectories).",https://keras.io/api/data_loading/image
must,"Since the pipeline processes batches of images that must all have
  the same size, this must be provided.",https://keras.io/api/data_loading/image
only,Only used if validation_split is set.,https://keras.io/api/data_loading/image
should,"If a file object was
  used instead of a filename, this parameter should always be used.",https://keras.io/api/data_loading/image
should,"targets[i] should be the target
  corresponding to the window that starts at index i
  (see example 2 below).",https://keras.io/api/data_loading/timeseries
only,"Pass None if you don't have target data (in this case the dataset
  will only yield the input data).",https://keras.io/api/data_loading/timeseries
only,"If not, the dataset yields
only batch_of_sequences.",https://keras.io/api/data_loading/timeseries
should,"The resulting dataset should consist samples with
20 timestamps each.",https://keras.io/api/data_loading/timeseries
should,The samples should not overlap.,https://keras.io/api/data_loading/timeseries
only,Only .,https://keras.io/api/data_loading/text
should,"If labels is ""inferred"", it should contain
  subdirectories, each containing text files for a class.",https://keras.io/api/data_loading/text
should,"Labels should be sorted according
  to the alphanumeric order of the text file paths
  (obtained via os.",https://keras.io/api/data_loading/text
only,"""binary"" means that the labels (there can be only 2)
    are encoded as float32 scalars with values 0 or 1
    (e.",https://keras.io/api/data_loading/text
only,"""binary"" means that the labels (there can be only 2)
    are encoded as float32 scalars with values 0 or 1
    (e.",https://keras.io/api/data_loading/text
only,"class_names: Only valid if ""labels"" is ""inferred"".",https://keras.io/api/data_loading/text
must,"This is the explicit list of class names
  (must match names of subdirectories).",https://keras.io/api/data_loading/text
only,Only used if validation_split is set.,https://keras.io/api/data_loading/text
only,Only .,https://keras.io/api/data_loading/audio
should,"If labels is ""inferred"", it should contain subdirectories,
  each containing audio files for a class.",https://keras.io/api/data_loading/audio
should,"Labels should be sorted according to the
  alphanumeric order of the audio file paths
  (obtained via os.",https://keras.io/api/data_loading/audio
only,"for categorical_crossentropy loss)
""binary"" means that the labels (there can be only 2)
  are encoded as float32 scalars with values 0
  or 1 (e.",https://keras.io/api/data_loading/audio
only,"""binary"" means that the labels (there can be only 2)
  are encoded as float32 scalars with values 0
  or 1 (e.",https://keras.io/api/data_loading/audio
only,"class_names: Only valid if ""labels"" is ""inferred"".",https://keras.io/api/data_loading/audio
must,"This is the explicit list of class names
  (must match names of subdirectories).",https://keras.io/api/data_loading/audio
only,Only used if validation_split is set.,https://keras.io/api/data_loading/audio
only,"This allows for quick filtering operations such as:
""only consider the top 10,000 most
common words, but eliminate the top 20 most common words"".",https://keras.io/api/datasets/imdb
only,"Words are
  ranked by how often they occur (in the training set) and only
  the num_words most frequent words are kept.",https://keras.io/api/datasets/imdb
note,"Note: The 'out of vocabulary' character is only used for
words that were present in the training set but are not included
because they're not making the num_words cut here.",https://keras.io/api/datasets/imdb
only,"Note: The 'out of vocabulary' character is only used for
words that were present in the training set but are not included
because they're not making the num_words cut here.",https://keras.io/api/datasets/imdb
only,"This allows for quick filtering operations such as:
""only consider the top 10,000 most
common words, but eliminate the top 20 most common words"".",https://keras.io/api/datasets/reuters
only,"Words are
  ranked by how often they occur (in the training set) and only
  the num_words most frequent words are kept.",https://keras.io/api/datasets/reuters
note,"Note: The 'out of vocabulary' character is only used for
words that were present in the training set but are not included
because they're not making the num_words cut here.",https://keras.io/api/datasets/reuters
only,"Note: The 'out of vocabulary' character is only used for
words that were present in the training set but are not included
because they're not making the num_words cut here.",https://keras.io/api/datasets/reuters
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/xception
only,"input_shape: optional shape tuple, only to be specified
  if include_top is False (otherwise the input shape
  has to be (299, 299, 3).",https://keras.io/api/applications/xception
should,"It should have exactly 3 inputs channels,
  and width and height should be no smaller than 71.",https://keras.io/api/applications/xception
only,"classes: optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/xception
only,"When loading pretrained weights, classifier_activation can
  only be None or ""softmax"".",https://keras.io/api/applications/xception
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet_v2
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet_v2
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet_v2
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet_v2
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet_v2
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet_v2
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet_v2
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet_v2
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet_v2
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet_v2
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet_v2
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet_v2
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet_v2
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet_v2
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet_v2
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet_v2
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet_v2
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet_v2
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet_v2
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet_v2
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet_v2
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet_v2
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet_v2
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet_v2
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet_v2
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet_v2
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet_v2
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet_v2
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet_v2
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet_v2
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/efficientnet_v2
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/efficientnet_v2
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/efficientnet_v2
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/efficientnet_v2
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/efficientnet_v2
note,Note: Each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/convnext
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/convnext
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/convnext
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/convnext
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/convnext
note,Note: Each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/convnext
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/convnext
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/convnext
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/convnext
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/convnext
note,Note: Each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/convnext
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/convnext
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/convnext
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/convnext
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/convnext
note,Note: Each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/convnext
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/convnext
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/convnext
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/convnext
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/convnext
note,Note: Each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/convnext
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False.",https://keras.io/api/applications/convnext
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/convnext
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/convnext
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/convnext
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/vgg
only,"input_shape: optional shape tuple, only to be specified
  if include_top is False (otherwise the input shape
  has to be (224, 224, 3)
  (with channels_last data format) or
  (3, 224, 224) (with ""channels_first"" data format).",https://keras.io/api/applications/vgg
should,"It should have exactly 3 input channels,
  and width and height should be no smaller than 32.",https://keras.io/api/applications/vgg
only,"classes: optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/vgg
only,"When loading pretrained weights, classifier_activation
  can only be None or ""softmax"".",https://keras.io/api/applications/vgg
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/vgg
only,"input_shape: optional shape tuple, only to be specified
  if include_top is False (otherwise the input shape
  has to be (224, 224, 3)
  (with channels_last data format) or
  (3, 224, 224) (with ""channels_first"" data format).",https://keras.io/api/applications/vgg
should,"It should have exactly 3 input channels,
  and width and height should be no smaller than 32.",https://keras.io/api/applications/vgg
only,"classes: optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/vgg
only,"When loading pretrained weights, classifier_activation can
  only be None or ""softmax"".",https://keras.io/api/applications/vgg
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/resnet
only,"input_shape: optional shape tuple, only to be specified if include_top
  is False (otherwise the input shape has to be (224, 224, 3)
  (with ""channels_last"" data format) or (3, 224, 224)
  (with ""channels_first"" data format).",https://keras.io/api/applications/resnet
should,"It should have exactly 3
  inputs channels, and width and height should be no smaller than 32.",https://keras.io/api/applications/resnet
only,"classes: optional number of classes to classify images into, only to be
  specified if include_top is True, and if no weights argument is
  specified.",https://keras.io/api/applications/resnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/resnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/resnet
only,"input_shape: optional shape tuple, only to be specified if include_top
  is False (otherwise the input shape has to be (224, 224, 3)
  (with ""channels_last"" data format) or (3, 224, 224)
  (with ""channels_first"" data format).",https://keras.io/api/applications/resnet
should,"It should have exactly 3
  inputs channels, and width and height should be no smaller than 32.",https://keras.io/api/applications/resnet
only,"classes: optional number of classes to classify images into, only to be
  specified if include_top is True, and if no weights argument is
  specified.",https://keras.io/api/applications/resnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/resnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/resnet
only,"input_shape: optional shape tuple, only to be specified if include_top
  is False (otherwise the input shape has to be (224, 224, 3)
  (with ""channels_last"" data format) or (3, 224, 224)
  (with ""channels_first"" data format).",https://keras.io/api/applications/resnet
should,"It should have exactly 3
  inputs channels, and width and height should be no smaller than 32.",https://keras.io/api/applications/resnet
only,"classes: optional number of classes to classify images into, only to be
  specified if include_top is True, and if no weights argument is
  specified.",https://keras.io/api/applications/resnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/resnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/resnet
only,"input_shape: optional shape tuple, only to be specified if include_top
  is False (otherwise the input shape has to be (224, 224, 3)
  (with ""channels_last"" data format) or (3, 224, 224)
  (with ""channels_first"" data format).",https://keras.io/api/applications/resnet
should,"It should have exactly 3
  inputs channels, and width and height should be no smaller than 32.",https://keras.io/api/applications/resnet
only,"classes: optional number of classes to classify images into, only to be
  specified if include_top is True, and if no weights argument is
  specified.",https://keras.io/api/applications/resnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/resnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/resnet
only,"input_shape: optional shape tuple, only to be specified if include_top
  is False (otherwise the input shape has to be (224, 224, 3)
  (with ""channels_last"" data format) or (3, 224, 224)
  (with ""channels_first"" data format).",https://keras.io/api/applications/resnet
should,"It should have exactly 3
  inputs channels, and width and height should be no smaller than 32.",https://keras.io/api/applications/resnet
only,"classes: optional number of classes to classify images into, only to be
  specified if include_top is True, and if no weights argument is
  specified.",https://keras.io/api/applications/resnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/resnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/resnet
only,"input_shape: optional shape tuple, only to be specified if include_top
  is False (otherwise the input shape has to be (224, 224, 3)
  (with ""channels_last"" data format) or (3, 224, 224)
  (with ""channels_first"" data format).",https://keras.io/api/applications/resnet
should,"It should have exactly 3
  inputs channels, and width and height should be no smaller than 32.",https://keras.io/api/applications/resnet
only,"classes: optional number of classes to classify images into, only to be
  specified if include_top is True, and if no weights argument is
  specified.",https://keras.io/api/applications/resnet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/resnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/mobilenet
only,"input_shape: Optional shape tuple, only to be specified if include_top
  is False (otherwise the input shape has to be (224, 224, 3)
  (with ""channels_last"" data format) or (3, 224, 224)
  (with ""channels_first"" data format).",https://keras.io/api/applications/mobilenet
should,"It should have exactly 3 inputs channels, and width and
  height should be no smaller than 32.",https://keras.io/api/applications/mobilenet
only,"classes: Optional number of classes to classify images into,
  only to be specified if include_top is True, and if
  no weights argument is specified.",https://keras.io/api/applications/mobilenet
only,"When loading pretrained weights, classifier_activation
  can only be None or ""softmax"".",https://keras.io/api/applications/mobilenet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/mobilenet
only,"input_shape: Optional shape tuple, only to be specified if include_top
  is False (otherwise the input shape has to be (224, 224, 3)
  (with ""channels_last"" data format) or (3, 224, 224)
  (with ""channels_first"" data format).",https://keras.io/api/applications/mobilenet
should,"It should have exactly 3 inputs channels, and width and
  height should be no smaller than 32.",https://keras.io/api/applications/mobilenet
only,"classes: Optional number of classes to classify images into,
  only to be specified if include_top is True, and if
  no weights argument is specified.",https://keras.io/api/applications/mobilenet
only,"When loading pretrained weights, classifier_activation
  can only be None or ""softmax"".",https://keras.io/api/applications/mobilenet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/mobilenet
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/mobilenet
only,"classes: Integer, optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/mobilenet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/mobilenet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/mobilenet
should,It should have exactly 3 inputs channels.,https://keras.io/api/applications/mobilenet
only,"classes: Integer, optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/mobilenet
only,"When loading pretrained weights, classifier_activation can only
  be None or ""softmax"".",https://keras.io/api/applications/mobilenet
note,"Note that the data format convention used by the model is
the one specified in your Keras config at ~/.",https://keras.io/api/applications/densenet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/densenet
only,"input_shape: optional shape tuple, only to be specified
if include_top is False (otherwise the input shape
has to be (224, 224, 3) (with 'channels_last' data format)
or (3, 224, 224) (with 'channels_first' data format).",https://keras.io/api/applications/densenet
should,"It should have exactly 3 inputs channels,
and width and height should be no smaller than 32.",https://keras.io/api/applications/densenet
only,"classes: optional number of classes to classify images
into, only to be specified if include_top is True, and
if no weights argument is specified.",https://keras.io/api/applications/densenet
only,"When loading pretrained weights,
classifier_activation can only be None or ""softmax"".",https://keras.io/api/applications/densenet
note,"Note that the data format convention used by the model is
the one specified in your Keras config at ~/.",https://keras.io/api/applications/densenet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/densenet
only,"input_shape: optional shape tuple, only to be specified
if include_top is False (otherwise the input shape
has to be (224, 224, 3) (with 'channels_last' data format)
or (3, 224, 224) (with 'channels_first' data format).",https://keras.io/api/applications/densenet
should,"It should have exactly 3 inputs channels,
and width and height should be no smaller than 32.",https://keras.io/api/applications/densenet
only,"classes: optional number of classes to classify images
into, only to be specified if include_top is True, and
if no weights argument is specified.",https://keras.io/api/applications/densenet
only,"When loading pretrained weights,
classifier_activation can only be None or ""softmax"".",https://keras.io/api/applications/densenet
note,"Note that the data format convention used by the model is
the one specified in your Keras config at ~/.",https://keras.io/api/applications/densenet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/densenet
only,"input_shape: optional shape tuple, only to be specified
if include_top is False (otherwise the input shape
has to be (224, 224, 3) (with 'channels_last' data format)
or (3, 224, 224) (with 'channels_first' data format).",https://keras.io/api/applications/densenet
should,"It should have exactly 3 inputs channels,
and width and height should be no smaller than 32.",https://keras.io/api/applications/densenet
only,"classes: optional number of classes to classify images
into, only to be specified if include_top is True, and
if no weights argument is specified.",https://keras.io/api/applications/densenet
only,"When loading pretrained weights,
classifier_activation can only be None or ""softmax"".",https://keras.io/api/applications/densenet
note,"Note that the data format convention used by the model is
the one specified in your Keras config at ~/.",https://keras.io/api/applications/nasnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/nasnet
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False (otherwise the input shape
  has to be (331, 331, 3) for NASNetLarge.",https://keras.io/api/applications/nasnet
should,"It should have exactly 3 inputs channels,
  and width and height should be no smaller than 32.",https://keras.io/api/applications/nasnet
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/nasnet
only,"When loading pretrained weights, classifier_activation
  can only be None or ""softmax"".",https://keras.io/api/applications/nasnet
note,"Note that the data format convention used by the model is
the one specified in your Keras config at ~/.",https://keras.io/api/applications/nasnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/nasnet
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False (otherwise the input shape
  has to be (224, 224, 3) for NASNetMobile
  It should have exactly 3 inputs channels,
  and width and height should be no smaller than 32.",https://keras.io/api/applications/nasnet
should,"input_shape: Optional shape tuple, only to be specified
  if include_top is False (otherwise the input shape
  has to be (224, 224, 3) for NASNetMobile
  It should have exactly 3 inputs channels,
  and width and height should be no smaller than 32.",https://keras.io/api/applications/nasnet
only,"classes: Optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/nasnet
only,"When loading pretrained weights, classifier_activation can
  only be None or ""softmax"".",https://keras.io/api/applications/nasnet
note,Note: each Keras Application expects a specific kind of input preprocessing.,https://keras.io/api/applications/inceptionv3
only,"input_shape: Optional shape tuple, only to be specified
  if include_top is False (otherwise the input shape
  has to be (299, 299, 3) (with channels_last data format)
  or (3, 299, 299) (with channels_first data format).",https://keras.io/api/applications/inceptionv3
should,"It should have exactly 3 inputs channels,
  and width and height should be no smaller than 75.",https://keras.io/api/applications/inceptionv3
only,"classes: optional number of classes to classify images
  into, only to be specified if include_top is True, and
  if no weights argument is specified.",https://keras.io/api/applications/inceptionv3
only,"When loading pretrained weights, classifier_activation
  can only be None or ""softmax"".",https://keras.io/api/applications/inceptionv3
note,"Note: each Keras Application expects a specific kind of
input preprocessing.",https://keras.io/api/applications/inceptionresnetv2
only,"input_shape: optional shape tuple, only to be specified
  if include_top is False (otherwise the input shape
  has to be (299, 299, 3)
  (with 'channels_last' data format)
  or (3, 299, 299) (with 'channels_first' data format).",https://keras.io/api/applications/inceptionresnetv2
should,"It should have exactly 3 inputs channels,
  and width and height should be no smaller than 75.",https://keras.io/api/applications/inceptionresnetv2
only,"classes: optional number of classes to classify images
  into, only to be specified if include_top is True,
  and if no weights argument is specified.",https://keras.io/api/applications/inceptionresnetv2
only,"When loading pretrained weights,
  classifier_activation can only be None or ""softmax"".",https://keras.io/api/applications/inceptionresnetv2
only,"Typically you only need to interact with dtype policies when using mixed
precision, which is the use of float16 or bfloat16 for computations and
float32 for variables.",https://keras.io/api/mixed_precision/policy
only,"(8,) for a data parallel only distribution,
  or (4, 2) for a model+data parallel distribution.",https://keras.io/api/distribution/layout_map
should,"The length of the axis_names should match to
  the rank of the shape.",https://keras.io/api/distribution/layout_map
should,"axes: tuple of strings that should map to the axis_names in
  a DeviceMesh.",https://keras.io/api/distribution/layout_map
only,"The device_mesh argument is expected to be a DeviceMesh instance,
and is expected to be 1D only.",https://keras.io/api/distribution/data_parallel
warning,"In case that the mesh has multiple axes,
then the first axis will be treated as the data parallel dimension
(and a warning will be raised).",https://keras.io/api/distribution/data_parallel
should,"The axis names of the
  TensorLayouts should match to the axis names in the
  device_mesh, or exception will be raised.",https://keras.io/api/distribution/model_parallel
note,"Note: in a distributed setting, global devices are returned.",https://keras.io/api/distribution/distribution_utils
should,It should be called before any computations.,https://keras.io/api/distribution/distribution_utils
note,"Note that the parameters can also be injected via enviornment variables,
which can be better controlled by the launch script at startup time.",https://keras.io/api/distribution/distribution_utils
note,"Note that for JAX
  backend, only the address for job 0 (coodinator) is needed.",https://keras.io/api/distribution/distribution_utils
only,"Note that for JAX
  backend, only the address for job 0 (coodinator) is needed.",https://keras.io/api/distribution/distribution_utils
should,"The value
  should be ranged from 0 to num_processes - 1.",https://keras.io/api/distribution/distribution_utils
note,"Also note that for JAX backend, the job_addresses can be further
reduced to just the master/coordinator address, which is
- __10.",https://keras.io/api/distribution/distribution_utils
must,"In order to get different values at each call, you must use a
SeedGenerator instead as the seed argument.",https://keras.io/api/random/seed_generator
should,"Each row
  should define a categorical distibution with the unnormalized
  log-probabilities for all classes.",https://keras.io/api/random/random_ops
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/random/random_ops
only,"Only floating point types are
  supported.",https://keras.io/api/random/random_ops
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/random/random_ops
only,"Only floating point types are
  supported.",https://keras.io/api/random/random_ops
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/random/random_ops
must,dtype must be an integer type.,https://keras.io/api/random/random_ops
only,"Only integer types are
  supported.",https://keras.io/api/random/random_ops
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/random/random_ops
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/random/random_ops
only,"Only floating point types are
  supported.",https://keras.io/api/random/random_ops
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/random/random_ops
must,"dtype must be a floating point type, the default range is [0, 1).",https://keras.io/api/random/random_ops
only,"Only floating point types are
  supported.",https://keras.io/api/random/random_ops
note,"Note that an initializer seeded with an integer
  or None (unseeded) will produce the same random values
  across multiple calls.",https://keras.io/api/random/random_ops
only,"show_layer_activations: Display layer activations (only for layers that
  have an activation property).",https://keras.io/api/utils/model_plotting_utils
note,A Jupyter notebook Image object if Jupyter is installed.,https://keras.io/api/utils/model_plotting_utils
note,This enables in-line display of the model plots in notebooks.,https://keras.io/api/utils/model_plotting_utils
only,"show_layer_activations: Display layer activations (only for layers that
  have an activation property).",https://keras.io/api/utils/model_plotting_utils
note,"Note that all features can be referred to by their string name,
e.",https://keras.io/api/utils/feature_space
only,"A ""symbolic tensor""
can be understood as a placeholder – it does not
contain any actual numerical data, only a shape and dtype.",https://keras.io/api/utils/tensor_utils
note,"Note that the TensorFlow seed is set even if you're not using TensorFlow
as your backend framework, since many workflows leverage tf.",https://keras.io/api/utils/python_utils
warning,⚠️ Warning on malicious downloads ⚠️,https://keras.io/api/utils/python_utils
should,"stateful_metrics: Iterable of string names of metrics that should not
  be averaged over time.",https://keras.io/api/utils/python_utils
must,"Every PyDataset must implement the __getitem__() and the __len__()
methods.",https://keras.io/api/utils/python_utils
should,"The __getitem__() method should return a complete batch
(not a single sample), and the __len__ method should return
the number of batches in the dataset (rather than the number of samples).",https://keras.io/api/utils/python_utils
only,"However it can only be set to
  True if your dataset can be safely pickled.",https://keras.io/api/utils/python_utils
note,Notes:,https://keras.io/api/utils/python_utils
only,"This structure guarantees that the model will only train
    once on each sample per epoch, which is not the case
    with Python generators.",https://keras.io/api/utils/python_utils
note,"This provides the best experience when using Keras in an interactive
environment such as a shell or a notebook.",https://keras.io/api/utils/config_utils
note,"Note: It is not recommended to set this to ""float16"" for training,
as this will likely cause numeric stability issues.",https://keras.io/api/utils/config_utils
only,"To prevent the users from depending on inactive hyperparameter values, only
active hyperparameters should have values in HyperParameters.",https://keras.io/api/keras_tuner/hyperparameters
should,"To prevent the users from depending on inactive hyperparameter values, only
active hyperparameters should have values in HyperParameters.",https://keras.io/api/keras_tuner/hyperparameters
must,"Must be unique for each
  HyperParameter instance in the search space.",https://keras.io/api/keras_tuner/hyperparameters
must,"Must be unique for each
  HyperParameter instance in the search space.",https://keras.io/api/keras_tuner/hyperparameters
must,"Values must be int, float,
  str, or bool.",https://keras.io/api/keras_tuner/hyperparameters
must,All values must be of the same type.,https://keras.io/api/keras_tuner/hyperparameters
should,"ordered: Optional boolean, whether the values passed should be
  considered to have an ordering.",https://keras.io/api/keras_tuner/hyperparameters
must,Must be False for any other values.,https://keras.io/api/keras_tuner/hyperparameters
must,"Must be unique for each
  HyperParameter instance in the search space.",https://keras.io/api/keras_tuner/hyperparameters
must,"Must be unique for each
  HyperParameter instance in the search space.",https://keras.io/api/keras_tuner/hyperparameters
note,"Note that unlike Python's range function, max_value is included in
the possible values this parameter can take on.",https://keras.io/api/keras_tuner/hyperparameters
must,"Must be unique for each
  HyperParameter instance in the search space.",https://keras.io/api/keras_tuner/hyperparameters
only,"All HyperParameters created under this scope will only be active when
the parent HyperParameter specified by parent_name is equal to one
of the values passed in parent_values.",https://keras.io/api/keras_tuner/hyperparameters
note,"Note that any Python code under this scope will execute regardless of
whether the condition is met.",https://keras.io/api/keras_tuner/hyperparameters
only,"If the parent HyperParameter is for model selection, the
HyperParameters in a model should only be active when the model
selected, which can be implemented using conditional_scope.",https://keras.io/api/keras_tuner/hyperparameters
should,"If the parent HyperParameter is for model selection, the
HyperParameters in a model should only be active when the model
selected, which can be implemented using conditional_scope.",https://keras.io/api/keras_tuner/hyperparameters
only,"A HyperModel subclass only needs to implement a
build(self, hp) method, which creates a keras.",https://keras.io/api/keras_tuner/hypermodels/
note,"Note: All pretrained weights should be used with unnormalized pixel
intensities in the range [0, 255] if include_rescaling=True or in the range
[0, 1] if including_rescaling=False.",https://keras.io/api/keras_cv/models/
should,"Note: All pretrained weights should be used with unnormalized pixel
intensities in the range [0, 255] if include_rescaling=True or in the range
[0, 1] if including_rescaling=False.",https://keras.io/api/keras_cv/models/
note,Note that all backbone presets are also applicable to the tasks.,https://keras.io/api/keras_cv/models/
note,"Note: All pretrained weights should be used with unnormalized pixel
intensities in the range [0, 255] if include_rescaling=True or in the range
[0, 1] if including_rescaling=False.",https://keras.io/api/keras_cv/models/
should,"Note: All pretrained weights should be used with unnormalized pixel
intensities in the range [0, 255] if include_rescaling=True or in the range
[0, 1] if including_rescaling=False.",https://keras.io/api/keras_cv/models/
must,"These presets are not inference-ready, and must be
fine-tuned for a given task!",https://keras.io/api/keras_nlp/models/
note,"Note: The links provided will lead to the model card or to the official README, 
if no model card has been provided by the author.",https://keras.io/api/keras_nlp/models/
note,"Note: The links provided will lead to the model card or to the official README, 
if no model card has been provided by the author.",https://keras.io/api/keras_nlp/models/
should,"Tokenizers should generally be applied inside a
tf.",https://keras.io/api/keras_nlp/tokenizers/
must,Must end in .,https://keras.io/api/models/model_saving_apis/model_saving_and_loading
should,"overwrite: Whether we should overwrite any existing model at
  the target location, or instead ask the user via
  an interactive prompt.",https://keras.io/api/models/model_saving_apis/model_saving_and_loading
only,"Only the ""keras"" format is
  supported at this time.",https://keras.io/api/models/model_saving_apis/model_saving_and_loading
note,Note that model.,https://keras.io/api/models/model_saving_apis/model_saving_and_loading
should,"overwrite: Whether we should overwrite any existing model at the target
  location, or instead ask the user via an interactive prompt.",https://keras.io/api/models/model_saving_apis/model_saving_and_loading
note,Note that model.,https://keras.io/api/models/model_saving_apis/model_saving_and_loading
only,"This argument is only
  applicable to the Keras v3 model format.",https://keras.io/api/models/model_saving_apis/model_saving_and_loading
note,"Note that the model variables may have different name values
(var.",https://keras.io/api/models/model_saving_apis/model_saving_and_loading
only,Weights-only saving & loading,https://keras.io/api/models/model_saving_apis/weights_saving_and_loading
must,Must end in .,https://keras.io/api/models/model_saving_apis/weights_saving_and_loading
should,"overwrite: Whether we should overwrite any existing model
  at the target location, or instead ask the user
  via an interactive prompt.",https://keras.io/api/models/model_saving_apis/weights_saving_and_loading
should,"This means the architecture should be the same as when the
weights were saved.",https://keras.io/api/models/model_saving_apis/weights_saving_and_loading
note,"Note that layers that don't have weights are not
taken into account in the topological ordering, so adding or removing
layers is fine as long as they don't have weights.",https://keras.io/api/models/model_saving_apis/weights_saving_and_loading
warning,"A warning will be displayed
for each skipped layer.",https://keras.io/api/models/model_saving_apis/weights_saving_and_loading
note,"Note that
clone_model will not preserve the uniqueness of shared objects within the
model (e.",https://keras.io/api/models/model_saving_apis/model_config_serialization
note,"Note that subclassed models cannot be cloned by default,
since their internal layer structure is not known.",https://keras.io/api/models/model_saving_apis/model_config_serialization
note,Note on resource tracking:,https://keras.io/api/models/model_saving_apis/export
only,"registered_name is only used for
  non-built-in classes.",https://keras.io/api/models/model_saving_apis/serialization_utils
only,"This argument is only
  applicable to the Keras v3 model format.",https://keras.io/api/models/model_saving_apis/serialization_utils
note,"Note that to be serialized and deserialized, classes must implement the
get_config() method.",https://keras.io/api/models/model_saving_apis/serialization_utils
must,"Note that to be serialized and deserialized, classes must implement the
get_config() method.",https://keras.io/api/models/model_saving_apis/serialization_utils
note,"Note that
  this is the first argument passed into the decorator.",https://keras.io/api/models/model_saving_apis/serialization_utils
note,"If not
  provided or None, the class' name will be used (note that this is
  the case when the decorator is used with only one argument, which
  becomes the package).",https://keras.io/api/models/model_saving_apis/serialization_utils
only,"If not
  provided or None, the class' name will be used (note that this is
  the case when the decorator is used with only one argument, which
  becomes the package).",https://keras.io/api/models/model_saving_apis/serialization_utils
note,"Note that, if sparse is False, sparse tensors can still
  be passed into the input - they will be densified with a default
  value of 0.",https://keras.io/api/layers/core_layers/input
only,"This feature is only supported with the TensorFlow
  backend.",https://keras.io/api/layers/core_layers/input
should,Should be unique in a model (do not reuse the same name twice).,https://keras.io/api/layers/core_layers/input
only,"Dense implements the operation:
output = activation(dot(input, kernel) + bias)
where activation is the element-wise activation function
passed as the activation argument, kernel is a weights matrix
created by the layer, and bias is a bias vector created by the layer
(only applicable if use_bias is True).",https://keras.io/api/layers/core_layers/dense
note,"Note: If the input to the layer has a rank greater than 2, Dense
computes the dot product between the inputs and the kernel along the
last axis of the inputs and axis 0 of the kernel (using tf.",https://keras.io/api/layers/core_layers/dense
must,"This equation must be a valid einsum string of the form
  ab,bc->ac, .",https://keras.io/api/layers/core_layers/einsum_dense
should,"Each character in the bias_axes string
  should correspond to a character in the output portion
  of the equation string.",https://keras.io/api/layers/core_layers/einsum_dense
only,"Because we are using ellipsis notation and have specified only one axis, the
output_shape arg is a single value.",https://keras.io/api/layers/core_layers/einsum_dense
only,This layer can only be used on positive integer inputs of a fixed range.,https://keras.io/api/layers/core_layers/embedding
should,"mask_zero: Boolean, whether or not the input value 0 is a special
  ""padding"" value that should be masked out.",https://keras.io/api/layers/core_layers/embedding
should,"If mask_zero is set to True, as a consequence,
  index 0 cannot be used in the vocabulary (input_dim should
  equal size of vocabulary + 1).",https://keras.io/api/layers/core_layers/embedding
not support,"If any downstream layer does not support masking yet receives such
an input mask, an exception will be raised.",https://keras.io/api/layers/core_layers/masking
note,"Note: in the Keras masking convention, a masked timestep is denoted by
a mask value of False, while a non-masked (i.",https://keras.io/api/layers/core_layers/masking
note,"usable) timestep
is denoted by a mask value of True.",https://keras.io/api/layers/core_layers/masking
warning,WARNING: Lambda layers have (de)serialization limitations!,https://keras.io/api/layers/core_layers/lambda
only,"They should only be loaded in the same environment where
they were saved.",https://keras.io/api/layers/core_layers/lambda
should,"They should only be loaded in the same environment where
they were saved.",https://keras.io/api/layers/core_layers/lambda
only,"If a tuple, it only specifies
  the first dimension onward; sample dimension is assumed
  either the same as the input:
  output_shape = (input_shape[0], ) + output_shape or,
  the input is None and the sample dimension is also None:
  output_shape = (None, ) + output_shape.",https://keras.io/api/layers/core_layers/lambda
should,"This layer should be used as a placeholder when no operation is to be
performed.",https://keras.io/api/layers/core_layers/identity
should,"Useful when modeling temporal data
  where the model should not violate the temporal order.",https://keras.io/api/layers/convolution_layers/convolution1d
must,Input channels and filters must both be divisible by groups.,https://keras.io/api/layers/convolution_layers/convolution1d
must,"The
  function must take as input the unprojected variable and must return
  the projected variable (which must have the same shape).",https://keras.io/api/layers/convolution_layers/convolution1d
must,Input channels and filters must both be divisible by groups.,https://keras.io/api/layers/convolution_layers/convolution2d
must,"The
  function must take as input the unprojected variable and must return
  the projected variable (which must have the same shape).",https://keras.io/api/layers/convolution_layers/convolution2d
must,Input channels and filters must both be divisible by groups.,https://keras.io/api/layers/convolution_layers/convolution3d
must,"The
  function must take as input the unprojected variable and must return
  the projected variable (which must have the same shape).",https://keras.io/api/layers/convolution_layers/convolution3d
only,"If only one int is specified, the same
  stride size will be used for all dimensions.",https://keras.io/api/layers/convolution_layers/separable_convolution1d
only,"If only one int is specified,
  the same dilation rate will be used for all dimensions.",https://keras.io/api/layers/convolution_layers/separable_convolution1d
must,"The
  function must take as input the unprojected variable and must return
  the projected variable (which must have the same shape).",https://keras.io/api/layers/convolution_layers/separable_convolution1d
only,"If only one int is specified, the same
  stride size will be used for all dimensions.",https://keras.io/api/layers/convolution_layers/separable_convolution2d
only,"If only one int is specified,
  the same dilation rate will be used for all dimensions.",https://keras.io/api/layers/convolution_layers/separable_convolution2d
must,"The
  function must take as input the unprojected variable and must return
  the projected variable (which must have the same shape).",https://keras.io/api/layers/convolution_layers/separable_convolution2d
must,"The
  function must take as input the unprojected variable and must return
  the projected variable (which must have the same shape).",https://keras.io/api/layers/convolution_layers/depthwise_convolution1d
must,"The
  function must take as input the unprojected variable and must return
  the projected variable (which must have the same shape).",https://keras.io/api/layers/convolution_layers/depthwise_convolution2d
must,"The
  function must take as input the unprojected variable and must return
  the projected variable (which must have the same shape).",https://keras.io/api/layers/convolution_layers/convolution1d_transpose
must,"The
  function must take as input the unprojected variable and must return
  the projected variable (which must have the same shape).",https://keras.io/api/layers/convolution_layers/convolution2d_transpose
must,"The
  function must take as input the unprojected variable and must return
  the projected variable (which must have the same shape).",https://keras.io/api/layers/convolution_layers/convolution3d_transpose
only,"If only one integer is specified, the same
  window length will be used for all dimensions.",https://keras.io/api/layers/pooling_layers/max_pooling2d
only,"If only one int is specified, the
  same stride size will be used for all dimensions.",https://keras.io/api/layers/pooling_layers/max_pooling2d
only,"If only one integer is specified, the same
  window length will be used for all dimensions.",https://keras.io/api/layers/pooling_layers/max_pooling3d
only,"If only one int is specified, the
  same stride size will be used for all dimensions.",https://keras.io/api/layers/pooling_layers/max_pooling3d
only,"If only one integer is specified, the same
  window length will be used for all dimensions.",https://keras.io/api/layers/pooling_layers/average_pooling2d
only,"If only one int is specified, the
  same stride size will be used for all dimensions.",https://keras.io/api/layers/pooling_layers/average_pooling2d
only,"If only one integer is specified, the same
  window length will be used for all dimensions.",https://keras.io/api/layers/pooling_layers/average_pooling3d
only,"If only one int is specified, the
  same stride size will be used for all dimensions.",https://keras.io/api/layers/pooling_layers/average_pooling3d
should,"mask: Binary tensor of shape (batch_size, steps) indicating whether
  a given step should be masked (excluded from the average).",https://keras.io/api/layers/pooling_layers/global_average_pooling1d
should,"use_bias: Boolean, (default True), whether the layer
  should use a bias vector.",https://keras.io/api/layers/recurrent_layers/lstm
only,Unrolling is only suitable for short sequences.,https://keras.io/api/layers/recurrent_layers/lstm
should,"mask: Binary tensor of shape (samples, timesteps) indicating whether
  a given timestep should be masked  (optional).",https://keras.io/api/layers/recurrent_layers/lstm
should,"An individual True entry indicates that the corresponding timestep
  should be utilized, while a False entry indicates that the
  corresponding timestep should be ignored.",https://keras.io/api/layers/recurrent_layers/lstm
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/lstm
only,"This is only relevant if dropout or
  recurrent_dropout is used  (optional).",https://keras.io/api/layers/recurrent_layers/lstm
should,"use_bias: Boolean, (default True), whether the layer
  should use a bias vector.",https://keras.io/api/layers/recurrent_layers/lstm_cell
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/lstm_cell
only,"Only relevant when dropout or
  recurrent_dropout is used.",https://keras.io/api/layers/recurrent_layers/lstm_cell
only,"The second variant is compatible with CuDNNGRU (GPU-only) and allows
inference on CPU.",https://keras.io/api/layers/recurrent_layers/gru
should,"use_bias: Boolean, (default True), whether the layer
  should use a bias vector.",https://keras.io/api/layers/recurrent_layers/gru
only,Unrolling is only suitable for short sequences.,https://keras.io/api/layers/recurrent_layers/gru
should,"mask: Binary tensor of shape (samples, timesteps) indicating whether
  a given timestep should be masked  (optional).",https://keras.io/api/layers/recurrent_layers/gru
should,"An individual True entry indicates that the corresponding timestep
  should be utilized, while a False entry indicates that the
  corresponding timestep should be ignored.",https://keras.io/api/layers/recurrent_layers/gru
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/gru
only,"This is only relevant if dropout or
  recurrent_dropout is used  (optional).",https://keras.io/api/layers/recurrent_layers/gru
should,"use_bias: Boolean, (default True), whether the layer
  should use a bias vector.",https://keras.io/api/layers/recurrent_layers/gru_cell
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/gru_cell
only,"Only relevant when dropout or
  recurrent_dropout is used.",https://keras.io/api/layers/recurrent_layers/gru_cell
only,Unrolling is only suitable for short sequences.,https://keras.io/api/layers/recurrent_layers/simple_rnn
should,"mask: Binary tensor of shape [batch, timesteps] indicating whether
  a given timestep should be masked.",https://keras.io/api/layers/recurrent_layers/simple_rnn
should,"An individual True entry
  indicates that the corresponding timestep should be utilized,
  while a False entry indicates that the corresponding timestep
  should be ignored.",https://keras.io/api/layers/recurrent_layers/simple_rnn
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/simple_rnn
only,This is only relevant if dropout or recurrent_dropout is used.,https://keras.io/api/layers/recurrent_layers/simple_rnn
should,"Every input should be at least 3D, and the dimension of index one of the
first input will be considered to be the temporal dimension.",https://keras.io/api/layers/recurrent_layers/time_distributed
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/time_distributed
only,"This argument is passed to the
  wrapped layer (only if the layer supports this argument).",https://keras.io/api/layers/recurrent_layers/time_distributed
should,"mask: Binary tensor of shape (samples, timesteps) indicating whether
  a given timestep should be masked.",https://keras.io/api/layers/recurrent_layers/time_distributed
only,"This argument is passed to the
  wrapped layer (only if the layer supports this argument).",https://keras.io/api/layers/recurrent_layers/time_distributed
note,"Note that the recommended way to create new RNN layers is to write a
custom RNN cell and use it with keras.",https://keras.io/api/layers/recurrent_layers/bidirectional
note,"Note that the recommended way to create new RNN layers is to write a
custom RNN cell and use it with keras.",https://keras.io/api/layers/recurrent_layers/bidirectional
note,"Note that the provided backward_layer layer should have properties
  matching those of the layer argument, in particular
  it should have the same values for stateful, return_states,
  return_sequences, etc.",https://keras.io/api/layers/recurrent_layers/bidirectional
should,"Note that the provided backward_layer layer should have properties
  matching those of the layer argument, in particular
  it should have the same values for stateful, return_states,
  return_sequences, etc.",https://keras.io/api/layers/recurrent_layers/bidirectional
should,"In addition, backward_layer
  and layer should have different go_backwards argument values.",https://keras.io/api/layers/recurrent_layers/bidirectional
note,"Note: instantiating a Bidirectional layer from an existing RNN layer
instance will not reuse the weights state of the RNN layer instance – the
Bidirectional layer will have freshly initialized weights.",https://keras.io/api/layers/recurrent_layers/bidirectional
only,Unrolling is only suitable for short sequences.,https://keras.io/api/layers/recurrent_layers/conv_lstm1d
should,"mask: Binary tensor of shape (samples, timesteps) indicating whether a
  given timestep should be masked.",https://keras.io/api/layers/recurrent_layers/conv_lstm1d
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/conv_lstm1d
only,This is only relevant if dropout or recurrent_dropout are set.,https://keras.io/api/layers/recurrent_layers/conv_lstm1d
only,Unrolling is only suitable for short sequences.,https://keras.io/api/layers/recurrent_layers/conv_lstm2d
should,"mask: Binary tensor of shape (samples, timesteps) indicating whether a
  given timestep should be masked.",https://keras.io/api/layers/recurrent_layers/conv_lstm2d
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/conv_lstm2d
only,This is only relevant if dropout or recurrent_dropout are set.,https://keras.io/api/layers/recurrent_layers/conv_lstm2d
only,Unrolling is only suitable for short sequences.,https://keras.io/api/layers/recurrent_layers/conv_lstm3d
should,"mask: Binary tensor of shape (samples, timesteps) indicating whether a
  given timestep should be masked.",https://keras.io/api/layers/recurrent_layers/conv_lstm3d
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/conv_lstm3d
only,This is only relevant if dropout or recurrent_dropout are set.,https://keras.io/api/layers/recurrent_layers/conv_lstm3d
note,"The call method of the
cell can also take the optional argument constants, see
section ""Note on passing external constants"" below.",https://keras.io/api/layers/recurrent_layers/rnn
should,"The returned initial state should have
shape (batch_size, cell.",https://keras.io/api/layers/recurrent_layers/rnn
note,"The call method of the
cell can also take the optional argument constants, see
section ""Note on passing external constants"" below.",https://keras.io/api/layers/recurrent_layers/rnn
should,"The returned initial state should have
shape (batch_size, cell.",https://keras.io/api/layers/recurrent_layers/rnn
only,Unrolling is only suitable for short sequences.,https://keras.io/api/layers/recurrent_layers/rnn
should,Whether the output should use zeros for the masked timesteps.,https://keras.io/api/layers/recurrent_layers/rnn
note,"Note that this field is only used when return_sequences
  is True and mask is provided.",https://keras.io/api/layers/recurrent_layers/rnn
only,"Note that this field is only used when return_sequences
  is True and mask is provided.",https://keras.io/api/layers/recurrent_layers/rnn
should,"mask: Binary tensor of shape [batch_size, timesteps]
  indicating whether a given timestep should be masked.",https://keras.io/api/layers/recurrent_layers/rnn
should,"An individual True entry indicates that the corresponding
  timestep should be utilized, while a False entry indicates
  that the corresponding timestep should be ignored.",https://keras.io/api/layers/recurrent_layers/rnn
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/rnn
note,Note on using statefulness in RNNs:,https://keras.io/api/layers/recurrent_layers/rnn
should,"It should be a tuple of integers, e.",https://keras.io/api/layers/recurrent_layers/rnn
note,Note on specifying the initial state of RNNs:,https://keras.io/api/layers/recurrent_layers/rnn
should,"The value of
initial_state should be a tensor or list of tensors representing
the initial state of the RNN layer.",https://keras.io/api/layers/recurrent_layers/rnn
should,"The value of
states should be a numpy array or list of numpy arrays representing
the initial state of the RNN layer.",https://keras.io/api/layers/recurrent_layers/rnn
should,"use_bias: Boolean, (default True), whether the layer
  should use a bias vector.",https://keras.io/api/layers/recurrent_layers/simple_rnn_cell
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/recurrent_layers/simple_rnn_cell
only,"Only relevant when dropout or
  recurrent_dropout is used.",https://keras.io/api/layers/recurrent_layers/simple_rnn_cell
only,"As such, the layer will only normalize its inputs during inference
after having been trained on data that has similar statistics as the
inference data.",https://keras.io/api/layers/normalization_layers/batch_normalization
should,"axis: Integer, the axis that should be normalized
  (typically the features axis).",https://keras.io/api/layers/normalization_layers/batch_normalization
only,synchronized: Only applicable with the TensorFlow backend.,https://keras.io/api/layers/normalization_layers/batch_normalization
should,"training: Python boolean indicating whether the layer should behave in
  training mode or in inference mode.",https://keras.io/api/layers/normalization_layers/batch_normalization
should,"mask: Binary tensor of shape broadcastable to inputs tensor, with
  True values indicating the positions for which mean and variance
  should be computed.",https://keras.io/api/layers/normalization_layers/batch_normalization
note,Note that:,https://keras.io/api/layers/normalization_layers/batch_normalization
must,"gamma and beta will span the axes of inputs specified in axis, and
this part of the inputs' shape must be fully defined.",https://keras.io/api/layers/normalization_layers/layer_normalization
note,"Note that other implementations of layer normalization may choose to define
gamma and beta over a separate set of axes from the axes being
normalized across.",https://keras.io/api/layers/normalization_layers/layer_normalization
only,"2018) with group size of 1
corresponds to a Layer Normalization that normalizes across height, width,
and channel and has gamma and beta span only the channel dimension.",https://keras.io/api/layers/normalization_layers/layer_normalization
must,"The input
  dimension must be divisible by the number of groups.",https://keras.io/api/layers/normalization_layers/group_normalization
note,"Note that the Dropout layer only applies when training is set to True
in call(), such that no values are dropped during inference.",https://keras.io/api/layers/regularization_layers/dropout
only,"Note that the Dropout layer only applies when training is set to True
in call(), such that no values are dropped during inference.",https://keras.io/api/layers/regularization_layers/dropout
should,"training: Python boolean indicating whether the layer should behave in
  training mode (adding dropout) or in inference mode (doing nothing).",https://keras.io/api/layers/regularization_layers/dropout
should,"In this case, SpatialDropout1D will help promote independence
between feature maps and should be used instead.",https://keras.io/api/layers/regularization_layers/spatial_dropout1d
should,"training: Python boolean indicating whether the layer
  should behave in training mode (applying dropout)
  or in inference mode (pass-through).",https://keras.io/api/layers/regularization_layers/spatial_dropout1d
should,"In this case, SpatialDropout2D will help promote independence
between feature maps and should be used instead.",https://keras.io/api/layers/regularization_layers/spatial_dropout2d
should,"training: Python boolean indicating whether the layer
  should behave in training mode (applying dropout)
  or in inference mode (pass-through).",https://keras.io/api/layers/regularization_layers/spatial_dropout2d
should,"In this case, SpatialDropout3D will help promote independence
between feature maps and should be used instead.",https://keras.io/api/layers/regularization_layers/spatial_dropout3d
should,"training: Python boolean indicating whether the layer
      should behave in training mode (applying dropout)
      or in inference mode (pass-through).",https://keras.io/api/layers/regularization_layers/spatial_dropout3d
only,"As it is a regularization layer, it is only active at training time.",https://keras.io/api/layers/regularization_layers/gaussian_dropout
should,"training: Python boolean indicating whether the layer should behave in
  training mode (adding dropout) or in inference mode (doing nothing).",https://keras.io/api/layers/regularization_layers/gaussian_dropout
should,"training: Python boolean indicating whether the layer should behave in
  training mode (adding alpha dropout) or in inference mode
  (doing nothing).",https://keras.io/api/layers/regularization_layers/alpha_dropout
only,"As it is a regularization layer, it is only active at training time.",https://keras.io/api/layers/regularization_layers/gaussian_noise
should,"training: Python boolean indicating whether the layer should behave in
  training mode (adding noise) or in inference mode (doing nothing).",https://keras.io/api/layers/regularization_layers/gaussian_noise
note,"Here
num_key_value_heads denotes number of groups, setting
num_key_value_heads to 1 is equivalent to multi-query attention, and
when num_key_value_heads is equal to num_query_heads it is equivalent
to multi-head attention.",https://keras.io/api/layers/attention_layers/group_query_attention
should,"return_attention_scores: A boolean to indicate whether the output
  should be (attention_output, attention_scores) if True, or
  attention_output if False.",https://keras.io/api/layers/attention_layers/group_query_attention
should,"training: Python boolean indicating whether the layer should behave in
  training mode (adding dropout) or in inference mode (no dropout).",https://keras.io/api/layers/attention_layers/group_query_attention
should,"return_attention_scores: A boolean to indicate whether the output should
  be (attention_output, attention_scores) if True, or
  attention_output if False.",https://keras.io/api/layers/attention_layers/multi_head_attention
should,"training: Python boolean indicating whether the layer should behave in
  training mode (adding dropout) or in inference mode (no dropout).",https://keras.io/api/layers/attention_layers/multi_head_attention
should,"training: Python boolean indicating whether the layer should behave in
        training mode (adding dropout) or in inference mode (no dropout).",https://keras.io/api/layers/attention_layers/attention
should,"training: Python boolean indicating whether the layer should behave in
        training mode (adding dropout) or in inference mode (no dropout).",https://keras.io/api/layers/attention_layers/additive_attention
must,"Arbitrary, although all dimensions in the input shape must be
known/fixed.",https://keras.io/api/layers/reshaping_layers/reshape
note,"Note: If inputs are shaped (batch,) without a feature axis, then
flattening adds an extra channel dimension and output shape is (batch, 1).",https://keras.io/api/layers/reshaping_layers/flatten
should,"If int: how many units should be trimmed off at the beginning and
  end of the cropping dimension (axis 1).",https://keras.io/api/layers/reshaping_layers/cropping1d
should,"If tuple of 2 ints: how many units should be trimmed off at the
  beginning and end of the cropping dimension
  ((left_crop, right_crop)).",https://keras.io/api/layers/reshaping_layers/cropping1d
should,"If int: how many units should be trimmed off at the beginning and
  end of the cropping dimension (axis 1).",https://keras.io/api/layers/reshaping_layers/cropping1d
should,"If tuple of 2 ints: how many units should be trimmed off at the
  beginning and end of the cropping dimension
  ((left_crop, right_crop)).",https://keras.io/api/layers/reshaping_layers/cropping1d
should,"The batch dimension should be
of same size for both the inputs, and axes should correspond
to the dimensions that have the same size in the corresponding
inputs.",https://keras.io/api/layers/merging_layers/dot
should,"If a tuple, should be two integers
  corresponding to the desired axis from the first input and the
  desired axis from the second input, respectively.",https://keras.io/api/layers/merging_layers/dot
note,"Note that the
  size of the two selected axes must match.",https://keras.io/api/layers/merging_layers/dot
must,"Note that the
  size of the two selected axes must match.",https://keras.io/api/layers/merging_layers/dot
only,"For example, if the incoming feature maps are
  from a 2D convolution with output shape
  (batch, height, width, channels), and you wish to share parameters
  across space so that each filter only has one set of parameters,
  set shared_axes=[1, 2].",https://keras.io/api/layers/activation_layers/prelu
must,"If it's a LazyModule
  instance, then its parameters must be initialized before
  passing the instance to TorchModuleWrapper (e.",https://keras.io/api/layers/backend_specific_layers/torch_module_wrapper
note,"Note that the reloaded
object retains none of the internal structure or custom methods of the
original object – it's a brand new layer created around the saved
function.",https://keras.io/api/layers/backend_specific_layers/tfsm_layer
only,"Only call endpoints with a single inputs tensor argument
(which may optionally be a dict/tuple/list of tensors) are supported.",https://keras.io/api/layers/backend_specific_layers/tfsm_layer
must,"If the hypermodel
  does not compile the models it generates, then this argument must be
  specified.",https://keras.io/api/keras_tuner/tuners/base_tuner
must,"If the hypermodel does not compile
  the models it generates, then this argument must be specified.",https://keras.io/api/keras_tuner/tuners/base_tuner
must,"If the hypermodel
  does not compile the models it generates, then this argument must
  be specified.",https://keras.io/api/keras_tuner/tuners/base_tuner
only,"Currently only single-worker strategies are
  supported.",https://keras.io/api/keras_tuner/tuners/base_tuner
should,"For models that report intermediate results to the Oracle, generally
load_model should load the best reported step by relying of
trial.",https://keras.io/api/keras_tuner/tuners/base_tuner
should,"This should include
  the value of the objective for this epoch.",https://keras.io/api/keras_tuner/tuners/base_tuner
should,"If return a dictionary, it should be a dictionary of the metrics to
track.",https://keras.io/api/keras_tuner/tuners/base_tuner
should,The values should be the metric values.,https://keras.io/api/keras_tuner/tuners/base_tuner
should,"If return a float, it should be the objective value.",https://keras.io/api/keras_tuner/tuners/base_tuner
should,"*fit_args: Positional arguments that should be passed to
  run_trial, for example the training and validation data.",https://keras.io/api/keras_tuner/tuners/base_tuner
should,"**fit_kwargs: Keyword arguments that should be passed to
  run_trial, for example the training and validation data.",https://keras.io/api/keras_tuner/tuners/base_tuner
should,"The value should be ""min"" or ""max"" indicating
  whether the objective value should be minimized or maximized.",https://keras.io/api/keras_tuner/tuners/objective
note,"Note that the oracle may interrupt the search
  before max_trial models have been tested if the search space has
  been exhausted.",https://keras.io/api/keras_tuner/tuners/random
should,"tune_new_entries: Boolean, whether hyperparameter entries that are
  requested by the hypermodel but that were not specified in
  hyperparameters should be added to the search space, or not.",https://keras.io/api/keras_tuner/tuners/random
note,"Note that the oracle may interrupt
  the search before max_trial models have been tested if the search
  space has been exhausted.",https://keras.io/api/keras_tuner/tuners/grid
should,"tune_new_entries: Boolean, whether hyperparameter entries that are
  requested by the hypermodel but that were not specified in
  hyperparameters should be added to the search space, or not.",https://keras.io/api/keras_tuner/tuners/grid
note,"Note that the oracle may interrupt the search
  before max_trial models have been tested if the search space has
  been exhausted.",https://keras.io/api/keras_tuner/tuners/bayesian
should,"tune_new_entries: Boolean, whether hyperparameter entries that are
  requested by the hypermodel but that were not specified in
  hyperparameters should be added to the search space, or not.",https://keras.io/api/keras_tuner/tuners/bayesian
should,"tune_new_entries: Boolean, whether hyperparameter entries that are
  requested by the hypermodel but that were not specified in
  hyperparameters should be added to the search space, or not.",https://keras.io/api/keras_tuner/tuners/hyperband
note,"Note that for this Tuner,
  the objective for the Oracle should always be set to
  Objective('score', direction='max').",https://keras.io/api/keras_tuner/tuners/sklearn
should,"Note that for this Tuner,
  the objective for the Oracle should always be set to
  Objective('score', direction='max').",https://keras.io/api/keras_tuner/tuners/sklearn
should,"Hyperband) should not be
  used with this Tuner.",https://keras.io/api/keras_tuner/tuners/sklearn
note,"Note that if you are
  searching across different Model families, the default scoring for
  these Models will often be different.",https://keras.io/api/keras_tuner/tuners/sklearn
should,"In this case you should
  supply scoring here in order to make sure your Models are being
  scored on the same metric.",https://keras.io/api/keras_tuner/tuners/sklearn
note,Note that these metrics do not affect the search process.,https://keras.io/api/keras_tuner/tuners/sklearn
only,"In a parallel tuning setting, there is only one Oracle instance.",https://keras.io/api/keras_tuner/oracles/base_oracle
note,"Note that the oracle may interrupt the search
  before max_trial models have been tested if the search space has
  been exhausted.",https://keras.io/api/keras_tuner/oracles/base_oracle
should,"tune_new_entries: Boolean, whether hyperparameter entries that are
  requested by the hypermodel but that were not specified in
  hyperparameters should be added to the search space, or not.",https://keras.io/api/keras_tuner/oracles/base_oracle
should,"This method should be overridden in subclasses and called in
create_trial in order to populate the hyperparameter space with
values.",https://keras.io/api/keras_tuner/oracles/base_oracle
should,"A dictionary with keys ""values"" and ""status"", where ""values"" is
a mapping of parameter names to suggested values, and ""status""
should be one of ""RUNNING"" (the trial can start normally), ""IDLE""
(the oracle is waiting on something and cannot create a trial), or
""STOPPED"" (the oracle has finished searching and no new trial should
be created).",https://keras.io/api/keras_tuner/oracles/base_oracle
only,"To avoid concurrent writing to the data, use @synchronized
to ensure the calls are synchronized, which only allows one call to run at a
time.",https://keras.io/api/keras_tuner/oracles/synchronized
only,"However, the decorator only support methods within classes, and cannot be
applied to standalone functions.",https://keras.io/api/keras_tuner/oracles/synchronized
only,"populate_space(), which is only
called by Oracle.",https://keras.io/api/keras_tuner/oracles/synchronized
note,"Note that the oracle may interrupt the search
  before max_trial models have been tested if the search space has
  been exhausted.",https://keras.io/api/keras_tuner/oracles/random
should,"tune_new_entries: Boolean, whether hyperparameter entries that are
  requested by the hypermodel but that were not specified in
  hyperparameters should be added to the search space, or not.",https://keras.io/api/keras_tuner/oracles/random
note,"Note that the oracle may interrupt
  the search before max_trial models have been tested if the search
  space has been exhausted.",https://keras.io/api/keras_tuner/oracles/grid
should,"tune_new_entries: Boolean, whether hyperparameter entries that are
  requested by the hypermodel but that were not specified in
  hyperparameters should be added to the search space, or not.",https://keras.io/api/keras_tuner/oracles/grid
note,"Note that the oracle may interrupt the search
  before max_trial models have been tested if the search space has
  been exhausted.",https://keras.io/api/keras_tuner/oracles/bayesian
should,"tune_new_entries: Boolean, whether hyperparameter entries that are
  requested by the hypermodel but that were not specified in
  hyperparameters should be added to the search space, or not.",https://keras.io/api/keras_tuner/oracles/bayesian
note,"Note that to use this Oracle with your own subclassed Tuner, your Tuner
class must be able to handle in Tuner.",https://keras.io/api/keras_tuner/oracles/hyperband
must,"Note that to use this Oracle with your own subclassed Tuner, your Tuner
class must be able to handle in Tuner.",https://keras.io/api/keras_tuner/oracles/hyperband
should,"The initial epoch the Trial should
    be started from.",https://keras.io/api/keras_tuner/oracles/hyperband
should,"The cumulative number of epochs this
    Trial should be trained.",https://keras.io/api/keras_tuner/oracles/hyperband
should,"tune_new_entries: Boolean, whether hyperparameter entries that are
  requested by the hypermodel but that were not specified in
  hyperparameters should be added to the search space, or not.",https://keras.io/api/keras_tuner/oracles/hyperband
should,"Users should subclass the HyperModel class to define their search spaces
by overriding build(), which creates and returns the Keras model.",https://keras.io/api/keras_tuner/hypermodels/base_hypermodel
should,"tunable: Boolean, whether the hyperparameters defined in this
  hypermodel should be added to search space.",https://keras.io/api/keras_tuner/hypermodels/base_hypermodel
must,"If False, either the
  search space for these parameters must be defined in advance, or
  the default values will be used.",https://keras.io/api/keras_tuner/hypermodels/base_hypermodel
must,"One of
  input_shape or input_tensor must be specified.",https://keras.io/api/keras_tuner/hypermodels/hyper_efficientnet
must,"One of input_shape or
  input_tensor must be specified.",https://keras.io/api/keras_tuner/hypermodels/hyper_efficientnet
only,"classes: Optional number of classes to classify images into, only to be
  specified if include_top is True, and if no weights argument is
  specified.",https://keras.io/api/keras_tuner/hypermodels/hyper_efficientnet
should,"The input shape of
the model should be (height, width, channels).",https://keras.io/api/keras_tuner/hypermodels/hyper_image_augment
must,"One of
  input_shape or input_tensor must be specified.",https://keras.io/api/keras_tuner/hypermodels/hyper_resnet
must,"One of input_shape or
  input_tensor must be specified.",https://keras.io/api/keras_tuner/hypermodels/hyper_resnet
only,"classes: Optional number of classes to classify images into, only to be
  specified if include_top is True, and if no weights argument is
  specified.",https://keras.io/api/keras_tuner/hypermodels/hyper_resnet
must,"One of
  input_shape or input_tensor must be specified.",https://keras.io/api/keras_tuner/hypermodels/hyper_xception
must,"One of input_shape or
  input_tensor must be specified.",https://keras.io/api/keras_tuner/hypermodels/hyper_xception
only,"classes: Optional number of classes to classify images into, only to be
  specified if include_top is True, and if no weights argument is
  specified.",https://keras.io/api/keras_tuner/hypermodels/hyper_xception
should,All values in the CENTER_XYWH format should be absolute pixel values.,https://keras.io/api/keras_cv/bounding_box/formats
should,All values in the XYWH format should be absolute pixel values.,https://keras.io/api/keras_cv/bounding_box/formats
should,All values in the XYXY format should be absolute pixel values.,https://keras.io/api/keras_cv/bounding_box/formats
should,All values in the YXYX format should be absolute pixel values.,https://keras.io/api/keras_cv/bounding_box/formats
note,"Note, this is equivalent to the gamma parameter in
  keras.",https://keras.io/api/keras_cv/losses/binary_focal_crossentropy
only,"CIoU loss not only penalizes the
bounding box coordinates but also considers the aspect ratio and center
distance of the boxes.",https://keras.io/api/keras_cv/losses/ciou_loss
should,"The length of the last dimension should be 4 to
represent the bounding boxes.",https://keras.io/api/keras_cv/losses/ciou_loss
only,"For this reason, it's commonly used with object detectors.",https://keras.io/api/keras_cv/losses/focal_loss
only,GIoU loss is a modified IoU loss commonly used for object detection.,https://keras.io/api/keras_cv/losses/giou_loss
should,"The length of the last dimension should be 4 to
represent the bounding boxes.",https://keras.io/api/keras_cv/losses/giou_loss
only,IoU loss is commonly used for object detection.,https://keras.io/api/keras_cv/losses/iou_loss
should,"The length of
the last dimension should be 4 to represent the bounding boxes.",https://keras.io/api/keras_cv/losses/iou_loss
must,"mode: must be one of
""linear"".",https://keras.io/api/keras_cv/losses/iou_loss
should,Tokenizers in the KerasNLP library should all subclass this layer.,https://keras.io/api/keras_nlp/tokenizers/tokenizer
should,"Subclassers should always implement the tokenize() method, which will also
be the default when calling the layer directly on inputs.",https://keras.io/api/keras_nlp/tokenizers/tokenizer
should,"Subclassers should implement get_vocabulary(), vocabulary_size(),
token_to_id() and id_to_token() if applicable.",https://keras.io/api/keras_nlp/tokenizers/tokenizer
only,"If a more custom pre-tokenization step is desired, the layer can be
configured to apply only the strict WordPiece algorithm by passing
lowercase=False, strip_accents=False and split=False.",https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer
should,"In
this case, inputs should be pre-split string tensors or ragged tensors.",https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer
should,"The output dtype can be controlled via the dtype argument, which should
be either an integer or string type.",https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer
should,"If
  passing a list, each element of the list should be a single
  WordPiece token string.",https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer
should,"If passing a filename, the file should be a
  plain text file containing a single WordPiece token per line.",https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer
should,"If False, input should be split (""pre-tokenized"")
  before calling the tokenizer, and passed as a dense or ragged tensor
  of whole words.",https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer
note,Note that this is applicable only when split is True.,https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer
only,Note that this is applicable only when split is True.,https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer
must,It must be included in the vocab.,https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer
should,"The output dtype can be controlled via the dtype
argument, which should be either an integer or string type.",https://keras.io/api/keras_nlp/tokenizers/sentence_piece_tokenizer
should,"Given the same vocabulary which maps tokens to ids, and merges
which describes BPE merge rules, it should provide the same output
as OpenAI implementation (https://github.",https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer
should,"If it is a
  string, it should be the file path to a json file.",https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer
should,"If it is a string,
  it should be the file path to merge rules.",https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer
should,"The merge rule file
  should have one merge rule per line.",https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer
must,"Special tokens
  must still be included in vocabulary.",https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer
should,"The output dtype can be controlled via the
dtype argument, which should be an integer type
(""int16"", ""int32"", etc.",https://keras.io/api/keras_nlp/tokenizers/byte_tokenizer
should,"The output dtype can be controlled via the dtype argument, which should be
an integer type (""int16"", ""int32"", etc.",https://keras.io/api/keras_nlp/tokenizers/unicode_codepoint_tokenizer
should,"For custom data loading and pretokenization (split=False), the input
data should be a tf.",https://keras.io/api/keras_nlp/tokenizers/compute_word_piece_vocabulary
should,"If False, input should be split (""pre-tokenized"")
  before calling the tokenizer, and passed as a dense or ragged tensor
  of whole words.",https://keras.io/api/keras_nlp/tokenizers/compute_word_piece_vocabulary
note,Note that this is applicable only when split is True.,https://keras.io/api/keras_nlp/tokenizers/compute_word_piece_vocabulary
only,Note that this is applicable only when split is True.,https://keras.io/api/keras_nlp/tokenizers/compute_word_piece_vocabulary
must,A list of tokens that must be included in the vocabulary.,https://keras.io/api/keras_nlp/tokenizers/compute_word_piece_vocabulary
must,"The model algorithm must be one of
  ""unigram"", ""bpe"", ""word"" or ""char"".",https://keras.io/api/keras_nlp/tokenizers/compute_sentence_piece_proto
should,"This layer is useful when tokenizing inputs for tasks like translation,
where each sequence should include a start and end marker.",https://keras.io/api/keras_nlp/preprocessing_layers/start_end_packer
should,"It should
be called after tokenization.",https://keras.io/api/keras_nlp/preprocessing_layers/start_end_packer
should,"Input data should be passed as tensors, tf.",https://keras.io/api/keras_nlp/preprocessing_layers/start_end_packer
should,"For
batched input, inputs should be a list of lists or a rank two tensor.",https://keras.io/api/keras_nlp/preprocessing_layers/start_end_packer
should,"For
unbatched inputs, each element should be a list or a rank one tensor.",https://keras.io/api/keras_nlp/preprocessing_layers/start_end_packer
must,"The dtype must match the dtype
  of the input tensors to the layer.",https://keras.io/api/keras_nlp/preprocessing_layers/start_end_packer
must,"The dtype must match the
  dtype of the input tensors to the layer.",https://keras.io/api/keras_nlp/preprocessing_layers/start_end_packer
should,"Each tuple element should contain
the tokens for a segment, passed as tensors, tf.",https://keras.io/api/keras_nlp/preprocessing_layers/multi_segment_packer
should,"For batched input, each element in the tuple of segments should be a list of
lists or a rank two tensor.",https://keras.io/api/keras_nlp/preprocessing_layers/multi_segment_packer
should,"For unbatched inputs, each element should be a
list or rank one tensor.",https://keras.io/api/keras_nlp/preprocessing_layers/multi_segment_packer
must,"The
  dtype must match the dtype of the input tensors to the layer.",https://keras.io/api/keras_nlp/preprocessing_layers/multi_segment_packer
must,"The dtype must match the dtype of the input tensors to the
  layer.",https://keras.io/api/keras_nlp/preprocessing_layers/multi_segment_packer
must,"The dtype must
  match the dtype of the input tensors to the layer.",https://keras.io/api/keras_nlp/preprocessing_layers/multi_segment_packer
should,"Input data should be passed as tensors, tf.",https://keras.io/api/keras_nlp/preprocessing_layers/random_swap
should,"For
batched input, inputs should be a list of lists or a rank two tensor.",https://keras.io/api/keras_nlp/preprocessing_layers/random_swap
should,"For
unbatched inputs, each element should be a list or a rank one tensor.",https://keras.io/api/keras_nlp/preprocessing_layers/random_swap
should,"skip_list: A list of token values that should not be considered
  candidates for deletion.",https://keras.io/api/keras_nlp/preprocessing_layers/random_swap
should,"A value of
  True indicates that the token should not be considered a
  candidate for deletion.",https://keras.io/api/keras_nlp/preprocessing_layers/random_swap
must,"This function must be tracable–it
  should consist of tensorflow operations.",https://keras.io/api/keras_nlp/preprocessing_layers/random_swap
should,"This function must be tracable–it
  should consist of tensorflow operations.",https://keras.io/api/keras_nlp/preprocessing_layers/random_swap
should,"A value of True
  indicates that should not be considered a candidate for deletion.",https://keras.io/api/keras_nlp/preprocessing_layers/random_swap
should,"Input data should be passed as tensors, tf.",https://keras.io/api/keras_nlp/preprocessing_layers/random_deletion
should,"For
batched input, inputs should be a list of lists or a rank two tensor.",https://keras.io/api/keras_nlp/preprocessing_layers/random_deletion
should,"For
unbatched inputs, each element should be a list or a rank one tensor.",https://keras.io/api/keras_nlp/preprocessing_layers/random_deletion
should,"skip_list: A list of token values that should not be considered
  candidates for deletion.",https://keras.io/api/keras_nlp/preprocessing_layers/random_deletion
should,"A value of
  True indicates that the token should not be considered a
  candidate for deletion.",https://keras.io/api/keras_nlp/preprocessing_layers/random_deletion
must,"This function must be tracable–it
  should consist of tensorflow operations.",https://keras.io/api/keras_nlp/preprocessing_layers/random_deletion
should,"This function must be tracable–it
  should consist of tensorflow operations.",https://keras.io/api/keras_nlp/preprocessing_layers/random_deletion
should,"A value of True
  indicates that should not be considered a candidate for deletion.",https://keras.io/api/keras_nlp/preprocessing_layers/random_deletion
should,"Input data should be passed as tensors, tf.",https://keras.io/api/keras_nlp/preprocessing_layers/masked_lm_mask_generator
should,"For
batched input, inputs should be a list of lists or a rank two tensor.",https://keras.io/api/keras_nlp/preprocessing_layers/masked_lm_mask_generator
should,"For
unbatched inputs, each element should be a list or a rank one tensor.",https://keras.io/api/keras_nlp/preprocessing_layers/masked_lm_mask_generator
should,"unselectable_token_ids: A list of tokens id that should not be
  considered eligible for masking.",https://keras.io/api/keras_nlp/preprocessing_layers/masked_lm_mask_generator
must,"mask_token_rate must be
  between 0 and 1 which indicates how often the mask_token is
  substituted for tokens selected for masking.",https://keras.io/api/keras_nlp/preprocessing_layers/masked_lm_mask_generator
must,"random_token_rate must be
  between 0 and 1 which indicates how often a random token is
  substituted for tokens selected for masking.",https://keras.io/api/keras_nlp/preprocessing_layers/masked_lm_mask_generator
note,"Note: mask_token_rate + random_token_rate <= 1,  and for
  (1 - mask_token_rate - random_token_rate), the token will not be
  changed.",https://keras.io/api/keras_nlp/preprocessing_layers/masked_lm_mask_generator
should,"Each element in mask_weights should be 0 or 1,
      1 means the corresponding position in mask_positions is an
      actual mask, 0 means it is a pad.",https://keras.io/api/keras_nlp/preprocessing_layers/masked_lm_mask_generator
should,"The input data to TransformerEncoder, should be
  of shape [batch_size, sequence_length, hidden_dim].",https://keras.io/api/keras_nlp/modeling_layers/transformer_encoder
should,"It indicates if the token should be
  masked because the token is introduced due to padding.",https://keras.io/api/keras_nlp/modeling_layers/transformer_encoder
should,"padding_mask should have shape [batch_size, sequence_length].",https://keras.io/api/keras_nlp/modeling_layers/transformer_encoder
should,"attention_mask should have shape
  [batch_size, sequence_length, sequence_length].",https://keras.io/api/keras_nlp/modeling_layers/transformer_encoder
must,"The number of inputs
must be consistent across all calls.",https://keras.io/api/keras_nlp/modeling_layers/transformer_decoder
only,"This is useful when building a ""decoder-only""
        transformer such as GPT-2.",https://keras.io/api/keras_nlp/modeling_layers/transformer_decoder
only,"For decoder
  only models (like GPT2), this should be left None.",https://keras.io/api/keras_nlp/modeling_layers/transformer_decoder
should,"For decoder
  only models (like GPT2), this should be left None.",https://keras.io/api/keras_nlp/modeling_layers/transformer_decoder
must,"decoder_padding_mask: a boolean Tensor, the padding mask of decoder
  sequence, must be of shape
  [batch_size, decoder_sequence_length].",https://keras.io/api/keras_nlp/modeling_layers/transformer_decoder
must,"Customized decoder
  sequence mask, must be of shape
  [batch_size, decoder_sequence_length, decoder_sequence_length].",https://keras.io/api/keras_nlp/modeling_layers/transformer_decoder
must,"encoder_padding_mask: a boolean Tensor, the padding mask of encoder
  sequence, must be of shape
  [batch_size, encoder_sequence_length].",https://keras.io/api/keras_nlp/modeling_layers/transformer_decoder
must,"Customized encoder
  sequence mask, must be of shape
  [batch_size, encoder_sequence_length, encoder_sequence_length].",https://keras.io/api/keras_nlp/modeling_layers/transformer_decoder
note,"Note on masking: In the official FNet code, padding tokens are added to the
the input.",https://keras.io/api/keras_nlp/modeling_layers/fnet_encoder
not support,"This layer does not supporting masking, but can be combined with a
keras.",https://keras.io/api/keras_nlp/modeling_layers/position_embedding
only,"Only the input shape
  will be used, as the position embedding does not depend on the
  input sequence content.",https://keras.io/api/keras_nlp/modeling_layers/position_embedding
must,"The input must be a tensor with shape a sequence dimension and a feature
dimension.",https://keras.io/api/keras_nlp/modeling_layers/rotary_embedding
must,"This can have
  any shape, but must contain both a sequence and feature axis.",https://keras.io/api/keras_nlp/modeling_layers/rotary_embedding
must,"The input must have shape
[batch_size, sequence_length, feature_size].",https://keras.io/api/keras_nlp/modeling_layers/sine_position_encoding
should,"tie_weights: Boolean, whether or not the matrix for embedding and
  the matrix for the reverse projection should share the same
  weights.",https://keras.io/api/keras_nlp/modeling_layers/reversible_embedding
should,"mask_zero: Boolean, whether or not the input value 0 is a special
  ""padding"" value that should be masked out.",https://keras.io/api/keras_nlp/modeling_layers/reversible_embedding
should,"mask_zero: Boolean, whether or not the input value 0 is a special
  ""padding"" value that should be masked out.",https://keras.io/api/keras_nlp/modeling_layers/token_and_position_embedding
should,"If mask_zero` is set to True, as a consequence, index 0 cannot be
  used in the vocabulary
  (input_dim should equal size of vocabulary + 1).",https://keras.io/api/keras_nlp/modeling_layers/token_and_position_embedding
should,"inputs: which should be a tensor of encoded tokens with shape
   (batch_size, sequence_length, hidden_dim).",https://keras.io/api/keras_nlp/modeling_layers/masked_lm_head
should,"mask_positions: which should be a tensor of integer positions to
   predict with shape (batch_size, masks_per_sequence).",https://keras.io/api/keras_nlp/modeling_layers/masked_lm_head
should,"The token encodings should usually be the last output of an encoder model,
and mask positions should be the integer positions you would like to
predict for the MaskedLM task.",https://keras.io/api/keras_nlp/modeling_layers/masked_lm_head
note,"Note that caching is useful only during inference and should not be used
during training.",https://keras.io/api/keras_nlp/modeling_layers/cached_multi_head_attention
only,"Note that caching is useful only during inference and should not be used
during training.",https://keras.io/api/keras_nlp/modeling_layers/cached_multi_head_attention
should,"Note that caching is useful only during inference and should not be used
during training.",https://keras.io/api/keras_nlp/modeling_layers/cached_multi_head_attention
note,"Note that during generative decoding, T is usually 1 (you are
generating a target sequence of length one to predict the next token).",https://keras.io/api/keras_nlp/modeling_layers/cached_multi_head_attention
must,"if cache is None,S*must equalSand match the shape ofattention_mask.",https://keras.io/api/keras_nlp/modeling_layers/cached_multi_head_attention
must,"If cache is
  None, S* must equal S and match the shape of
  attention_mask.",https://keras.io/api/keras_nlp/modeling_layers/cached_multi_head_attention
must,"The key/value cache, of shape
  [B, 2, S, num_heads, key_dims], where S must agree with the
  attention_mask shape.",https://keras.io/api/keras_nlp/modeling_layers/cached_multi_head_attention
must,Subclasses must implement this method.,https://keras.io/api/keras_nlp/samplers/samplers
should,"The number of beams that should be kept at each
  time-step.",https://keras.io/api/keras_nlp/samplers/beam_sampler
should,num_beams should be strictly positive.,https://keras.io/api/keras_nlp/samplers/beam_sampler
note,Note: This implementation is not suitable for fixed-size windows.,https://keras.io/api/keras_nlp/metrics/perplexity
should,"If True, y_pred (input to update_state()) should
  be the logits as returned by the model.",https://keras.io/api/keras_nlp/metrics/perplexity
note,"Note that if this field is provided, and
  if the sample_weight field in update_state() is also provided,
  we will compute the final sample_weight as the element-wise
  product of the mask and the sample_weight.",https://keras.io/api/keras_nlp/metrics/perplexity
note,"Note on input shapes:
For y_true and y_pred, this class supports scalar values and batch
inputs of shapes (), (batch_size,) and (batch_size, 1).",https://keras.io/api/keras_nlp/metrics/rouge_l
should,"Whether Porter Stemmer should be used to strip word
  suffixes to improve matching.",https://keras.io/api/keras_nlp/metrics/rouge_l
note,"Note on input shapes:
For y_true and y_pred, this class supports scalar values and batch
inputs of shapes (), (batch_size,) and (batch_size, 1).",https://keras.io/api/keras_nlp/metrics/rouge_n
should,"It should lie in
  range [1, 9].",https://keras.io/api/keras_nlp/metrics/rouge_n
should,"Whether Porter Stemmer should be used to strip word
  suffixes to improve matching.",https://keras.io/api/keras_nlp/metrics/rouge_n
note,"Note on input shapes:
For unbatched inputs, y_pred should be a tensor of shape (), and
y_true should be a tensor of shape (num_references,).",https://keras.io/api/keras_nlp/metrics/bleu
should,"Note on input shapes:
For unbatched inputs, y_pred should be a tensor of shape (), and
y_true should be a tensor of shape (num_references,).",https://keras.io/api/keras_nlp/metrics/bleu
should,"For batched
inputs, y_pred should be a tensor of shape (batch_size,),
and y_true should be a tensor of shape (batch_size, num_references).",https://keras.io/api/keras_nlp/metrics/bleu
note,"Note on input shapes:
y_true and y_pred can either be tensors of rank 1 or ragged tensors of
rank 2.",https://keras.io/api/keras_nlp/metrics/edit_distance
must,"The vocabulary for the layer must be either supplied on construction or
learned via adapt().",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
note,"Some notes on passing callables to customize splitting and normalization for
this layer:",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,"Any callable can be passed to this Layer, but if you want to serialize
   this object you should only pass functions that are registered Keras
   serializables (see keras.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
should,"Any callable can be passed to this Layer, but if you want to serialize
   this object you should only pass functions that are registered Keras
   serializables (see keras.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
should,"The callable
   should return a tensor of the same shape as the input.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
should,The callable should return a tf.,https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
should,"Tensor of dtype string
   with the first dimension containing the split tokens -
   in this example, we should see something like [[""string"", ""to"",
   ""split""], [""another"", ""string"", ""to"", ""split""]].",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
note,Note: This layer uses TensorFlow internally.,https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,"This should
  only be specified when adapting a vocabulary or when setting
  pad_to_max_tokens=True.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
should,"This should
  only be specified when adapting a vocabulary or when setting
  pad_to_max_tokens=True.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
note,"Note that this vocabulary
  contains 1 OOV token, so the effective number of tokens is
  (max_tokens - 1 - (1 if output_mode == ""int"" else 0)).",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
should,"Callable: Inputs will passed to the callable function,
    which should be standardized and returned.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
should,"Callable: Inputs will passed to the callable function,
    which should be standardized and returned.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
should,"Callable: Standardized inputs will passed to the callable
    function, which should be split and returned.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
should,"Callable: Standardized inputs will passed to the callable
    function, which should be split and returned.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,"For all other output modes, currently only rank 1 inputs
(and rank 2 outputs after splitting) are supported.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,"For all other output modes, currently only rank 1 inputs
(and rank 2 outputs after splitting) are supported.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,output_sequence_length: Only valid in INT mode.,https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,"pad_to_max_tokens: Only valid in  ""multi_hot"", ""count"",
  and ""tf_idf"" modes.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
should,"If passing a file path, the file should contain one line per term
  in the vocabulary.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,"idf_weights: Only valid when output_mode is ""tf_idf"".",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
must,"If the vocabulary argument is set,
  and output_mode is ""tf_idf"", this argument must be supplied.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,"Only applicable to ""int"" output mode.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,Only supported with TensorFlow backend.,https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,"Only applicable to ""multi_hot"", ""count"", and
  ""tf_idf"" output modes.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
only,"Only supported with TensorFlow
  backend.",https://keras.io/api/layers/preprocessing_layers/text/text_vectorization
must,"The mean and variance values for the layer must be either supplied on
construction or learned via adapt().",https://keras.io/api/layers/preprocessing_layers/numerical/normalization
should,"adapt() should
be called before fit(), evaluate(), or predict().",https://keras.io/api/layers/preprocessing_layers/numerical/normalization
should,"The axis or axes that should
  have a separate mean and variance for each index in the shape.",https://keras.io/api/layers/preprocessing_layers/numerical/normalization
note,"Note that in the specific case of batched scalar inputs where
  the only axis is the batch axis, the default will normalize
  each index in the batch separately.",https://keras.io/api/layers/preprocessing_layers/numerical/normalization
only,"Note that in the specific case of batched scalar inputs where
  the only axis is the batch axis, the default will normalize
  each index in the batch separately.",https://keras.io/api/layers/preprocessing_layers/numerical/normalization
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/numerical/discretization
should,"If this option is set, adapt() should not be called.",https://keras.io/api/layers/preprocessing_layers/numerical/discretization
should,"If this option is set,
  adapt() should be called to learn the bin boundaries.",https://keras.io/api/layers/preprocessing_layers/numerical/discretization
only,"Only applicable to ""one_hot"", ""multi_hot"",
  and ""count"" output modes.",https://keras.io/api/layers/preprocessing_layers/numerical/discretization
only,"Only supported with TensorFlow
  backend.",https://keras.io/api/layers/preprocessing_layers/numerical/discretization
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/categorical/category_encoding
should,num_tokens: The total number of tokens the layer should support.,https://keras.io/api/layers/preprocessing_layers/categorical/category_encoding
must,"All
  inputs to the layer must integers in the range 0 <= value <
  num_tokens, or an error will be thrown.",https://keras.io/api/layers/preprocessing_layers/categorical/category_encoding
only,"For all output modes, currently only output up to rank 2 is
  supported.",https://keras.io/api/layers/preprocessing_layers/categorical/category_encoding
note,Note: This layer internally uses TensorFlow.,https://keras.io/api/layers/preprocessing_layers/categorical/hashing
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/categorical/hashing
note,"Note that this includes the mask_value
  bin, so the effective number of bins is (num_bins - 1)
  if mask_value is set.",https://keras.io/api/layers/preprocessing_layers/categorical/hashing
should,These should be non-zero.,https://keras.io/api/layers/preprocessing_layers/categorical/hashing
only,"Only applicable to ""one_hot"", ""multi_hot"",
  and ""count"" output modes.",https://keras.io/api/layers/preprocessing_layers/categorical/hashing
only,"Only supported with TensorFlow
  backend.",https://keras.io/api/layers/preprocessing_layers/categorical/hashing
only,"This layer currently only performs crosses of scalar inputs and batches of
scalar inputs.",https://keras.io/api/layers/preprocessing_layers/categorical/hashed_crossing
note,Note: This layer wraps tf.,https://keras.io/api/layers/preprocessing_layers/categorical/hashed_crossing
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/categorical/hashed_crossing
only,"Only applicable to ""one_hot"" mode and only valid
  when using the TensorFlow backend.",https://keras.io/api/layers/preprocessing_layers/categorical/hashed_crossing
must,"The vocabulary for the layer must be either supplied on construction or
learned via adapt().",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
note,Note: This layer uses TensorFlow internally.,https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
only,"This should
  only be specified when adapting the vocabulary or when setting
  pad_to_max_tokens=True.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
should,"This should
  only be specified when adapting the vocabulary or when setting
  pad_to_max_tokens=True.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
note,"Note that this size includes the OOV
  and mask tokens.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
only,oov_token: Only used when invert is True.,https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
should,"If passing a file path, the file should contain one line per term
  in the vocabulary.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
only,"idf_weights: Only valid when output_mode is ""tf_idf"".",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
must,"If the vocabulary argument is set, and output_mode is
  ""tf_idf"", this argument must be supplied.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
only,"invert: Only valid when output_mode is ""int"".",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
only,"For all other output modes, currently only output up to rank 2
is supported.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
only,"For all other output modes, currently only output up to rank 2
is supported.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
only,"pad_to_max_tokens: Only applicable when output_mode is ""multi_hot"",
  ""count"", or ""tf_idf"".",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
only,"Only applicable to ""multi_hot"", ""count"", and
  ""tf_idf"" output modes.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
only,"Only supported with TensorFlow
  backend.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
note,"Note that the OOV token ""[UNK]"" has been added to the vocabulary.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
note,"Note that the output for OOV value 'm' is 0, while the output for OOV value
""z"" is 1.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
note,"Note that the first
num_oov_indices dimensions in the ont_hot encoding represent OOV values.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
note,"Note that the first
num_oov_indices dimensions in the multi_hot encoding represent OOV values.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
should,"These should be
provided along with the vocabulary.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
note,"Note that the idf_weight for OOV
values will default to the average of all idf weights passed in.",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
note,Note that the first index correspond to the oov token by default.,https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
note,"Also, note that
for the inverse to work, you must have already set the forward layer
vocabulary either directly or via adapt() before calling
get_vocabulary().",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
must,"Also, note that
for the inverse to work, you must have already set the forward layer
vocabulary either directly or via adapt() before calling
get_vocabulary().",https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup
must,"The vocabulary for the layer must be either supplied on construction or
learned via adapt().",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
note,Note: This layer uses TensorFlow internally.,https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
only,"This should
  only be specified when adapting the vocabulary or when setting
  pad_to_max_tokens=True.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
should,"This should
  only be specified when adapting the vocabulary or when setting
  pad_to_max_tokens=True.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
note,"Note that this size includes the OOV
  and mask tokens.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
only,oov_token: Only used when invert is True.,https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
should,"If passing a file path, the file should contain one line per term
  in the vocabulary.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
only,"idf_weights: Only valid when output_mode is ""tf_idf"".",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
must,"If the vocabulary argument is set, and output_mode is
  ""tf_idf"", this argument must be supplied.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
only,"invert: Only valid when output_mode is ""int"".",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
only,"For all other output modes, currently only output up to rank 2
is supported.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
only,"For all other output modes, currently only output up to rank 2
is supported.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
only,"pad_to_max_tokens: Only applicable when output_mode is ""multi_hot"",
  ""count"", or ""tf_idf"".",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
only,"Only applicable to ""multi_hot"", ""count"", and
  ""tf_idf"" output modes.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
only,"Only supported with TensorFlow
  backend.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
note,Note that the OOV token -1 have been added to the vocabulary.,https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
note,"Note that the output for OOV token 37 is 1, while the output for OOV token
1000 is 0.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
note,"Note that the first
num_oov_indices dimensions in the ont_hot encoding represent OOV values.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
should,"These should be
provided along with the vocabulary.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
note,"Note that the idf_weight for OOV
tokens will default to the average of all idf weights passed in.",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
note,Note that the first index correspond to the oov token by default.,https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
note,"Also, note that for the
inverse to work, you must have already set the forward layer vocabulary
either directly or via adapt() before calling get_vocabulary().",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
must,"Also, note that for the
inverse to work, you must have already set the forward layer vocabulary
either directly or via adapt() before calling get_vocabulary().",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
should,"The input
should be a 4D (batched) or 3D (unbatched) tensor in ""channels_last""
format.",https://keras.io/api/layers/preprocessing_layers/image_preprocessing/resizing
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/resizing
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/rescaling
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/image_preprocessing/center_crop
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_crop
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_flip
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_translation
note,"Note that when using torch backend, ""reflect"" is redirected to
""mirror"" (c d c b | a b c d | c b a b) because torch does not
support ""reflect"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_translation
note,"Note that torch backend does not support ""wrap"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_translation
not support,"Note that torch backend does not support ""wrap"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_translation
note,"Note that when using torch backend, ""reflect"" is redirected to
""mirror"" (c d c b | a b c d | c b a b) because torch does not
support ""reflect"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_translation
note,"Note that torch backend does not support ""wrap"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_translation
not support,"Note that torch backend does not support ""wrap"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_translation
only,"By default, random rotations are only applied during training.",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_rotation
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_rotation
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom
note,"Note that when using torch backend, ""reflect"" is redirected to
""mirror"" (c d c b | a b c d | c b a b) because torch does not
support ""reflect"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom
note,"Note that torch backend does not support ""wrap"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom
not support,"Note that torch backend does not support ""wrap"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom
note,"Note that when using torch backend, ""reflect"" is redirected to
""mirror"" (c d c b | a b c d | c b a b) because torch does not
support ""reflect"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom
note,"Note that torch backend does not support ""wrap"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom
not support,"Note that torch backend does not support ""wrap"".",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_contrast
note,Note: This layer is safe to use inside a tf.,https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_brightness
only,"When only one float is provided, eg, 0.",https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_brightness
should,"To implement your own schedule object, you should implement the __call__
method, which takes a step argument (scalar integer tensor, the
current training step count).",https://keras.io/api/optimizers/learning_rate_schedules/learning_rate_schedule#learningrateschedule-class
only,"An
example of this is if an image only has values [0, 1] out of the range
[0, 255], auto contrast will change the 1 values to be 255.",https://keras.io/api/keras_cv/layers/augmentation/auto_contrast
should,"Floats should be in the range [0, 1].",https://keras.io/api/keras_cv/layers/augmentation/grid_mask
should,"Floats should be in the range [0, 1].",https://keras.io/api/keras_cv/layers/augmentation/grid_mask
only,"As such this layer will commonly be the final step in an
augmentation pipeline.",https://keras.io/api/keras_cv/layers/augmentation/jittered_resize
should,"Magnitude
  should be a float in the range [0, 1].",https://keras.io/api/keras_cv/layers/augmentation/rand_augment
should,"Should be in the range
  [0, 1].",https://keras.io/api/keras_cv/layers/augmentation/rand_augment
should,"This
  should be set to False when performing object detection.",https://keras.io/api/keras_cv/layers/augmentation/rand_augment
should,"The layers
  passed should subclass BaseImageAugmentationLayer.",https://keras.io/api/keras_cv/layers/augmentation/random_augmentation_pipeline
only,"This offers a significant performance
  boost, but can only be used if all the layers provided to the
  layers argument support auto vectorization.",https://keras.io/api/keras_cv/layers/augmentation/random_augmentation_pipeline
should,The input images should have values in the [0-255] or [0-1] range.,https://keras.io/api/keras_cv/layers/augmentation/random_channel_shift
should,Values should be between 0.,https://keras.io/api/keras_cv/layers/augmentation/random_color_degeneration
should,"Values should
  be between 0.",https://keras.io/api/keras_cv/layers/augmentation/random_cutout
should,Values should be between 0.,https://keras.io/api/keras_cv/layers/augmentation/random_cutout
should,Values should be between 0.,https://keras.io/api/keras_cv/layers/augmentation/random_saturation
should,"Values should be
  between 0.",https://keras.io/api/keras_cv/layers/augmentation/random_sharpness
should,All provided values should be positive.,https://keras.io/api/keras_cv/layers/augmentation/random_shear
should,All provided values should be positive.,https://keras.io/api/keras_cv/layers/augmentation/random_shear
should,"Images passed to the layer should have
  values within value_range.",https://keras.io/api/keras_cv/layers/augmentation/solarization
should,"The
  addition value should be scaled according to the value range
  (0, 255), defaults to 0.",https://keras.io/api/keras_cv/layers/augmentation/solarization
only,"If specified, only pixel
  values above this threshold will be solarized.",https://keras.io/api/keras_cv/layers/augmentation/solarization
should,"The input
should be a 4D (batched) or 3D (unbatched) tensor in ""channels_last""
format.",https://keras.io/api/keras_cv/layers/preprocessing/resizing
should,"Input images should have values in the range of [0, 255].",https://keras.io/api/keras_cv/layers/preprocessing/grayscale
should,"Images passed to the layer should have
  values within value_range.",https://keras.io/api/keras_cv/layers/preprocessing/equalization
should,"Should be in the range [0, 256].",https://keras.io/api/keras_cv/layers/preprocessing/equalization
should,Should be in NHWC format.,https://keras.io/api/keras_cv/layers/preprocessing/equalization
should,"Images passed to the layer should have
     values within value_range.",https://keras.io/api/keras_cv/layers/preprocessing/posterization
must,"Must be a
     value between 1-8.",https://keras.io/api/keras_cv/layers/preprocessing/posterization
must,Must be between 0 and 1.,https://keras.io/api/keras_cv/layers/regularization/dropblock2d
should,"For best results, the value should be between 0.",https://keras.io/api/keras_cv/layers/regularization/dropblock2d
must,"Must be
  bigger than 0, and should not be bigger than the input feature map
  size.",https://keras.io/api/keras_cv/layers/regularization/dropblock2d
should,"Must be
  bigger than 0, and should not be bigger than the input feature map
  size.",https://keras.io/api/keras_cv/layers/regularization/dropblock2d
note,"Note that this layer drops individual
samples within a batch and not the entire batch.",https://keras.io/api/keras_cv/layers/regularization/drop_path
note,"Note that this layer DOES NOT drop a residual block across
individual samples but across the entire batch.",https://keras.io/api/keras_cv/layers/regularization/stochastic_depth
must,"Must be one of ""efficientnetv2_s"", ""efficientnetv2_m"", ""efficientnetv2_l"", ""efficientnetv2_b0"", ""efficientnetv2_b1"", ""efficientnetv2_b2"", ""efficientnetv2_b3"", ""efficientnetv2_s_imagenet"", ""efficientnetv2_b0_imagenet"", ""efficientnetv2_b1_imagenet"", ""efficientnetv2_b2_imagenet"".",https://keras.io/api/keras_cv/models/backbones/efficientnetv2
must,"Must be one of ""mobilenet_v3_small"", ""mobilenet_v3_large"", ""mobilenet_v3_large_imagenet"", ""mobilenet_v3_small_imagenet"".",https://keras.io/api/keras_cv/models/backbones/mobilenetv3
must,"Must be one of ""resnet18"", ""resnet34"", ""resnet50"", ""resnet101"", ""resnet152"", ""resnet50_imagenet"".",https://keras.io/api/keras_cv/models/backbones/resnet_v1
must,"Must be one of ""resnet18_v2"", ""resnet34_v2"", ""resnet50_v2"", ""resnet101_v2"", ""resnet152_v2"", ""resnet50_v2_imagenet"".",https://keras.io/api/keras_cv/models/backbones/resnet_v2
must,"Must be one of ""yolo_v8_xs_backbone"", ""yolo_v8_s_backbone"", ""yolo_v8_m_backbone"", ""yolo_v8_l_backbone"", ""yolo_v8_xl_backbone"", ""yolo_v8_xs_backbone_coco"", ""yolo_v8_s_backbone_coco"", ""yolo_v8_m_backbone_coco"", ""yolo_v8_l_backbone_coco"", ""yolo_v8_xl_backbone_coco"".",https://keras.io/api/keras_cv/models/backbones/yolo_v8
must,"Must be one of ""avg"", ""max"".",https://keras.io/api/keras_cv/models/tasks/image_classifier
must,"Must be one of ""resnet18"", ""resnet34"", ""resnet50"", ""resnet101"", ""resnet152"", ""resnet18_v2"", ""resnet34_v2"", ""resnet50_v2"", ""resnet101_v2"", ""resnet152_v2"", ""mobilenet_v3_small"", ""mobilenet_v3_large"", ""csp_darknet_tiny"", ""csp_darknet_s"", ""csp_darknet_m"", ""csp_darknet_l"", ""csp_darknet_xl"", ""efficientnetv1_b0"", ""efficientnetv1_b1"", ""efficientnetv1_b2"", ""efficientnetv1_b3"", ""efficientnetv1_b4"", ""efficientnetv1_b5"", ""efficientnetv1_b6"", ""efficientnetv1_b7"", ""efficientnetv2_s"", ""efficientnetv2_m"", ""efficientnetv2_l"", ""efficientnetv2_b0"", ""efficientnetv2_b1"", ""efficientnetv2_b2"", ""efficientnetv2_b3"", ""densenet121"", ""densenet169"", ""densenet201"", ""efficientnetlite_b0"", ""efficientnetlite_b1"", ""efficientnetlite_b2"", ""efficientnetlite_b3"", ""efficientnetlite_b4"", ""yolo_v8_xs_backbone"", ""yolo_v8_s_backbone"", ""yolo_v8_m_backbone"", ""yolo_v8_l_backbone"", ""yolo_v8_xl_backbone"", ""vitdet_base"", ""vitdet_large"", ""vitdet_huge"", ""resnet50_imagenet"", ""resnet50_v2_imagenet"", ""mobilenet_v3_large_imagenet"", ""mobilenet_v3_small_imagenet"", ""csp_darknet_tiny_imagenet"", ""csp_darknet_l_imagenet"", ""efficientnetv2_s_imagenet"", ""efficientnetv2_b0_imagenet"", ""efficientnetv2_b1_imagenet"", ""efficientnetv2_b2_imagenet"", ""densenet121_imagenet"", ""densenet169_imagenet"", ""densenet201_imagenet"", ""yolo_v8_xs_backbone_coco"", ""yolo_v8_s_backbone_coco"", ""yolo_v8_m_backbone_coco"", ""yolo_v8_l_backbone_coco"", ""yolo_v8_xl_backbone_coco"", ""vitdet_base_sa1b"", ""vitdet_large_sa1b"", ""vitdet_huge_sa1b"", ""resnet50_v2_imagenet_classifier"", ""efficientnetv2_s_imagenet_classifier"", ""efficientnetv2_b0_imagenet_classifier"", ""efficientnetv2_b1_imagenet_classifier"", ""efficientnetv2_b2_imagenet_classifier"", ""mobilenet_v3_large_imagenet_classifier"".",https://keras.io/api/keras_cv/models/tasks/image_classifier
should,"Classes should be represented by integers in the
  range [0, num_classes).",https://keras.io/api/keras_cv/models/tasks/retinanet
must,"If the default feature_pyramid is used,
  must implement the pyramid_level_inputs property with keys ""P3"", ""P4"",
  and ""P5"" and layer names as values.",https://keras.io/api/keras_cv/models/tasks/retinanet
only,"Only to be used when
  both label_encoder and prediction_decoder are both None.",https://keras.io/api/keras_cv/models/tasks/retinanet
must,"Must be one of ""resnet18"", ""resnet34"", ""resnet50"", ""resnet101"", ""resnet152"", ""resnet18_v2"", ""resnet34_v2"", ""resnet50_v2"", ""resnet101_v2"", ""resnet152_v2"", ""mobilenet_v3_small"", ""mobilenet_v3_large"", ""csp_darknet_tiny"", ""csp_darknet_s"", ""csp_darknet_m"", ""csp_darknet_l"", ""csp_darknet_xl"", ""efficientnetv1_b0"", ""efficientnetv1_b1"", ""efficientnetv1_b2"", ""efficientnetv1_b3"", ""efficientnetv1_b4"", ""efficientnetv1_b5"", ""efficientnetv1_b6"", ""efficientnetv1_b7"", ""efficientnetv2_s"", ""efficientnetv2_m"", ""efficientnetv2_l"", ""efficientnetv2_b0"", ""efficientnetv2_b1"", ""efficientnetv2_b2"", ""efficientnetv2_b3"", ""densenet121"", ""densenet169"", ""densenet201"", ""efficientnetlite_b0"", ""efficientnetlite_b1"", ""efficientnetlite_b2"", ""efficientnetlite_b3"", ""efficientnetlite_b4"", ""yolo_v8_xs_backbone"", ""yolo_v8_s_backbone"", ""yolo_v8_m_backbone"", ""yolo_v8_l_backbone"", ""yolo_v8_xl_backbone"", ""vitdet_base"", ""vitdet_large"", ""vitdet_huge"", ""resnet50_imagenet"", ""resnet50_v2_imagenet"", ""mobilenet_v3_large_imagenet"", ""mobilenet_v3_small_imagenet"", ""csp_darknet_tiny_imagenet"", ""csp_darknet_l_imagenet"", ""efficientnetv2_s_imagenet"", ""efficientnetv2_b0_imagenet"", ""efficientnetv2_b1_imagenet"", ""efficientnetv2_b2_imagenet"", ""densenet121_imagenet"", ""densenet169_imagenet"", ""densenet201_imagenet"", ""yolo_v8_xs_backbone_coco"", ""yolo_v8_s_backbone_coco"", ""yolo_v8_m_backbone_coco"", ""yolo_v8_l_backbone_coco"", ""yolo_v8_xl_backbone_coco"", ""vitdet_base_sa1b"", ""vitdet_large_sa1b"", ""vitdet_huge_sa1b"", ""retinanet_resnet50_pascalvoc"".",https://keras.io/api/keras_cv/models/tasks/retinanet
must,"Model, must implement the pyramid_level_inputs
  property with keys ""P2"", ""P3"", and ""P4"" and layer names as values.",https://keras.io/api/keras_cv/models/tasks/yolo_v8_detector
should,"Classes should be represented by integers in the
  range [0, num_classes).",https://keras.io/api/keras_cv/models/tasks/yolo_v8_detector
must,"Must be one of ""resnet18"", ""resnet34"", ""resnet50"", ""resnet101"", ""resnet152"", ""resnet18_v2"", ""resnet34_v2"", ""resnet50_v2"", ""resnet101_v2"", ""resnet152_v2"", ""mobilenet_v3_small"", ""mobilenet_v3_large"", ""csp_darknet_tiny"", ""csp_darknet_s"", ""csp_darknet_m"", ""csp_darknet_l"", ""csp_darknet_xl"", ""efficientnetv1_b0"", ""efficientnetv1_b1"", ""efficientnetv1_b2"", ""efficientnetv1_b3"", ""efficientnetv1_b4"", ""efficientnetv1_b5"", ""efficientnetv1_b6"", ""efficientnetv1_b7"", ""efficientnetv2_s"", ""efficientnetv2_m"", ""efficientnetv2_l"", ""efficientnetv2_b0"", ""efficientnetv2_b1"", ""efficientnetv2_b2"", ""efficientnetv2_b3"", ""densenet121"", ""densenet169"", ""densenet201"", ""efficientnetlite_b0"", ""efficientnetlite_b1"", ""efficientnetlite_b2"", ""efficientnetlite_b3"", ""efficientnetlite_b4"", ""yolo_v8_xs_backbone"", ""yolo_v8_s_backbone"", ""yolo_v8_m_backbone"", ""yolo_v8_l_backbone"", ""yolo_v8_xl_backbone"", ""vitdet_base"", ""vitdet_large"", ""vitdet_huge"", ""resnet50_imagenet"", ""resnet50_v2_imagenet"", ""mobilenet_v3_large_imagenet"", ""mobilenet_v3_small_imagenet"", ""csp_darknet_tiny_imagenet"", ""csp_darknet_l_imagenet"", ""efficientnetv2_s_imagenet"", ""efficientnetv2_b0_imagenet"", ""efficientnetv2_b1_imagenet"", ""efficientnetv2_b2_imagenet"", ""densenet121_imagenet"", ""densenet169_imagenet"", ""densenet201_imagenet"", ""yolo_v8_xs_backbone_coco"", ""yolo_v8_s_backbone_coco"", ""yolo_v8_m_backbone_coco"", ""yolo_v8_l_backbone_coco"", ""yolo_v8_xl_backbone_coco"", ""vitdet_base_sa1b"", ""vitdet_large_sa1b"", ""vitdet_huge_sa1b"", ""yolo_v8_m_pascalvoc"".",https://keras.io/api/keras_cv/models/tasks/yolo_v8_detector
note,"Note that the StableDiffusion API, as well as the APIs of the sub-components
of StableDiffusion (e.",https://keras.io/api/keras_cv/models/tasks/stable_diffusion
should,"ImageEncoder, DiffusionModel) should be considered
unstable at this point.",https://keras.io/api/keras_cv/models/tasks/stable_diffusion
note,"Note that
  only multiples of 128 are supported; the value provided will be
  rounded to the nearest valid value.",https://keras.io/api/keras_cv/models/tasks/stable_diffusion
only,"Note that
  only multiples of 128 are supported; the value provided will be
  rounded to the nearest valid value.",https://keras.io/api/keras_cv/models/tasks/stable_diffusion
note,"Note that
  only multiples of 128 are supported; the value provided will be
  rounded to the nearest valid value.",https://keras.io/api/keras_cv/models/tasks/stable_diffusion
only,"Note that
  only multiples of 128 are supported; the value provided will be
  rounded to the nearest valid value.",https://keras.io/api/keras_cv/models/tasks/stable_diffusion
must,"Must be one of ""albert_base_en_uncased"", ""albert_large_en_uncased"", ""albert_extra_large_en_uncased"", ""albert_extra_extra_large_en_uncased"".",https://keras.io/api/keras_nlp/models/albert/albert_tokenizer
should,Special care should be taken when using tf.,https://keras.io/api/keras_nlp/models/albert/albert_preprocessor
must,"Must be one of ""albert_base_en_uncased"", ""albert_large_en_uncased"", ""albert_extra_large_en_uncased"", ""albert_extra_extra_large_en_uncased"".",https://keras.io/api/keras_nlp/models/albert/albert_preprocessor
must,"num_layers: int, must be divisible by num_groups.",https://keras.io/api/keras_nlp/models/albert/albert_backbone
must,The hidden size must be divisible by the number of attention heads.,https://keras.io/api/keras_nlp/models/albert/albert_backbone
note,"Note that some computations,
  such as softmax and layer normalization, will always be done at
  float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/albert/albert_backbone
must,"Must be one of ""albert_base_en_uncased"", ""albert_large_en_uncased"", ""albert_extra_large_en_uncased"", ""albert_extra_extra_large_en_uncased"".",https://keras.io/api/keras_nlp/models/albert/albert_backbone
should,"If
  None, this model will not apply preprocessing, and inputs should
  be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/albert/albert_classifier
must,"Must be one of ""albert_base_en_uncased"", ""albert_large_en_uncased"", ""albert_extra_large_en_uncased"", ""albert_extra_extra_large_en_uncased"".",https://keras.io/api/keras_nlp/models/albert/albert_classifier
should,"If None, this model will not apply preprocessing, and
  inputs should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/albert/albert_masked_lm
must,"Must be one of ""albert_base_en_uncased"", ""albert_large_en_uncased"", ""albert_extra_large_en_uncased"", ""albert_extra_extra_large_en_uncased"".",https://keras.io/api/keras_nlp/models/albert/albert_masked_lm
must,"mask_token_rate must be
  between 0 and 1 which indicates how often the mask_token is
  substituted for tokens selected for masking.",https://keras.io/api/keras_nlp/models/albert/albert_masked_lm_preprocessor
must,"random_token_rate must be
  between 0 and 1 which indicates how often a random token is
  substituted for tokens selected for masking.",https://keras.io/api/keras_nlp/models/albert/albert_masked_lm_preprocessor
note,"Note: mask_token_rate + random_token_rate <= 1,  and for
  (1 - mask_token_rate - random_token_rate), the token will not be
  changed.",https://keras.io/api/keras_nlp/models/albert/albert_masked_lm_preprocessor
must,"Must be one of ""albert_base_en_uncased"", ""albert_large_en_uncased"", ""albert_extra_large_en_uncased"", ""albert_extra_extra_large_en_uncased"".",https://keras.io/api/keras_nlp/models/albert/albert_masked_lm_preprocessor
should,"If
  passing a list, each element of the list should be a single word
  piece token string.",https://keras.io/api/keras_nlp/models/bart/bart_tokenizer
should,"If passing a filename, the file should be a
  plain text file containing a single word piece token per line.",https://keras.io/api/keras_nlp/models/bart/bart_tokenizer
must,"Must be one of ""bert_tiny_en_uncased"", ""bert_small_en_uncased"", ""bert_medium_en_uncased"", ""bert_base_en_uncased"", ""bert_base_en"", ""bert_base_zh"", ""bert_base_multi"", ""bert_large_en_uncased"", ""bert_large_en"", ""bert_tiny_en_uncased_sst2"".",https://keras.io/api/keras_nlp/models/bart/bart_tokenizer
must,"Must be one of ""bert_tiny_en_uncased"", ""bert_small_en_uncased"", ""bert_medium_en_uncased"", ""bert_base_en_uncased"", ""bert_base_en"", ""bert_base_zh"", ""bert_base_multi"", ""bert_large_en_uncased"", ""bert_large_en"", ""bert_tiny_en_uncased_sst2"".",https://keras.io/api/keras_nlp/models/bart/bart_preprocessor
must,The hidden size must be divisible by the number of attention heads.,https://keras.io/api/keras_nlp/models/bart/bart_backbone
note,"Note that some computations,
  such as softmax and layer normalization, will always be done at
  float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/bart/bart_backbone
must,"Must be one of ""bert_tiny_en_uncased"", ""bert_small_en_uncased"", ""bert_medium_en_uncased"", ""bert_base_en_uncased"", ""bert_base_en"", ""bert_base_zh"", ""bert_base_multi"", ""bert_large_en_uncased"", ""bert_large_en"".",https://keras.io/api/keras_nlp/models/bart/bart_backbone
should,"If None, this model will not apply preprocessing, and inputs
  should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm
must,"Must be one of ""bart_base_en"", ""bart_large_en"", ""bart_large_en_cnn"".",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm
should,"If a preprocessor is attached to the model, inputs will be
preprocessed inside the generate() function and should match the
structure expected by the preprocessor layer (usually raw strings).",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm
should,"If a preprocessor is not attached, inputs should match the structure
expected by the backbone.",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm
should,"If a
  preprocessor is attached to the model, inputs should match
  the structure expected by the preprocessor layer.",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm
should,"If a
  preprocessor is not attached, inputs should match the
  structure expected the backbone model.",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm
should,"If preprocessor is None, inputs should be
  should be padded to the desired maximum length and this argument
  will be ignored.",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm
should,"Each value in the dictionary should be a tensor of single string
  sequences.",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm_preprocessor
should,"Should always be None as the layer generates labels by
  shifting the decoder input sequence one step to the left.",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm_preprocessor
should,"Should always be None as the layer
  generates label weights by shifting the padding mask one step to the
  left.",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm_preprocessor
must,"Must be one of ""bart_base_en"", ""bart_large_en"", ""bart_large_en_cnn"".",https://keras.io/api/keras_nlp/models/bart/bart_seq_2_seq_lm_preprocessor
should,"If
  passing a list, each element of the list should be a single word
  piece token string.",https://keras.io/api/keras_nlp/models/bert/bert_tokenizer
should,"If passing a filename, the file should be a
  plain text file containing a single word piece token per line.",https://keras.io/api/keras_nlp/models/bert/bert_tokenizer
must,"Must be one of ""bert_tiny_en_uncased"", ""bert_small_en_uncased"", ""bert_medium_en_uncased"", ""bert_base_en_uncased"", ""bert_base_en"", ""bert_base_zh"", ""bert_base_multi"", ""bert_large_en_uncased"", ""bert_large_en"", ""bert_tiny_en_uncased_sst2"".",https://keras.io/api/keras_nlp/models/bert/bert_tokenizer
must,"Must be one of ""bert_tiny_en_uncased"", ""bert_small_en_uncased"", ""bert_medium_en_uncased"", ""bert_base_en_uncased"", ""bert_base_en"", ""bert_base_zh"", ""bert_base_multi"", ""bert_large_en_uncased"", ""bert_large_en"", ""bert_tiny_en_uncased_sst2"".",https://keras.io/api/keras_nlp/models/bert/bert_preprocessor
must,The hidden size must be divisible by the number of attention heads.,https://keras.io/api/keras_nlp/models/bert/bert_backbone
note,"Note that some computations,
  such as softmax and layer normalization, will always be done at
  float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/bert/bert_backbone
must,"Must be one of ""bert_tiny_en_uncased"", ""bert_small_en_uncased"", ""bert_medium_en_uncased"", ""bert_base_en_uncased"", ""bert_base_en"", ""bert_base_zh"", ""bert_base_multi"", ""bert_large_en_uncased"", ""bert_large_en"".",https://keras.io/api/keras_nlp/models/bert/bert_backbone
should,"If
  None, this model will not apply preprocessing, and inputs should
  be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/bert/bert_classifier
must,"Must be one of ""bert_tiny_en_uncased"", ""bert_small_en_uncased"", ""bert_medium_en_uncased"", ""bert_base_en_uncased"", ""bert_base_en"", ""bert_base_zh"", ""bert_base_multi"", ""bert_large_en_uncased"", ""bert_large_en"", ""bert_tiny_en_uncased_sst2"".",https://keras.io/api/keras_nlp/models/bert/bert_classifier
should,"If None, this model will not apply preprocessing, and
  inputs should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/bert/bert_masked_lm
must,"Must be one of ""bert_tiny_en_uncased"", ""bert_small_en_uncased"", ""bert_medium_en_uncased"", ""bert_base_en_uncased"", ""bert_base_en"", ""bert_base_zh"", ""bert_base_multi"", ""bert_large_en_uncased"", ""bert_large_en"".",https://keras.io/api/keras_nlp/models/bert/bert_masked_lm
should,Should always be None as the layer generates labels.,https://keras.io/api/keras_nlp/models/bert/bert_masked_lm_preprocessor
should,"Should always be None as the layer
  generates label weights.",https://keras.io/api/keras_nlp/models/bert/bert_masked_lm_preprocessor
must,"Must be one of ""bert_tiny_en_uncased"", ""bert_small_en_uncased"", ""bert_medium_en_uncased"", ""bert_base_en_uncased"", ""bert_base_en"", ""bert_base_zh"", ""bert_base_multi"", ""bert_large_en_uncased"", ""bert_large_en"", ""bert_tiny_en_uncased_sst2"".",https://keras.io/api/keras_nlp/models/bert/bert_masked_lm_preprocessor
note,"Note: The mask token (""[MASK]"") is handled differently in this tokenizer.",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_tokenizer
must,"Must be one of ""deberta_v3_extra_small_en"", ""deberta_v3_small_en"", ""deberta_v3_base_en"", ""deberta_v3_large_en"", ""deberta_v3_base_multi"".",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_tokenizer
should,Special care should be taken when using tf.,https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_preprocessor
must,"Must be one of ""deberta_v3_extra_small_en"", ""deberta_v3_small_en"", ""deberta_v3_base_en"", ""deberta_v3_large_en"", ""deberta_v3_base_multi"".",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_preprocessor
note,"Note: DebertaV3Backbone has a performance issue on TPUs, and we recommend
other models for TPU training and inference.",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_backbone
must,The hidden size must be divisible by the number of attention heads.,https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_backbone
must,"The sequence length of the input must be less than
  max_sequence_length.",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_backbone
note,"Note that some computations,
  such as softmax and layer normalization, will always be done at
  float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_backbone
must,"Must be one of ""deberta_v3_extra_small_en"", ""deberta_v3_small_en"", ""deberta_v3_base_en"", ""deberta_v3_large_en"", ""deberta_v3_base_multi"".",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_backbone
note,"Note: DebertaV3Backbone has a performance issue on TPUs, and we recommend
other models for TPU training and inference.",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_classifier
should,"If
  None, this model will not apply preprocessing, and inputs should
  be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_classifier
must,"Must be one of ""deberta_v3_extra_small_en"", ""deberta_v3_small_en"", ""deberta_v3_base_en"", ""deberta_v3_large_en"", ""deberta_v3_base_multi"".",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_classifier
should,"If None, this model will not apply preprocessing, and
  inputs should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_masked_lm
must,"Must be one of ""deberta_v3_extra_small_en"", ""deberta_v3_small_en"", ""deberta_v3_base_en"", ""deberta_v3_large_en"", ""deberta_v3_base_multi"".",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_masked_lm
must,"mask_token_rate must be
  between 0 and 1 which indicates how often the mask_token is
  substituted for tokens selected for masking.",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_masked_lm_preprocessor
must,"random_token_rate must be
  between 0 and 1 which indicates how often a random token is
  substituted for tokens selected for masking.",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_masked_lm_preprocessor
note,"Note: mask_token_rate + random_token_rate <= 1,  and for
  (1 - mask_token_rate - random_token_rate), the token will not be
  changed.",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_masked_lm_preprocessor
must,"Must be one of ""deberta_v3_extra_small_en"", ""deberta_v3_small_en"", ""deberta_v3_base_en"", ""deberta_v3_large_en"", ""deberta_v3_base_multi"".",https://keras.io/api/keras_nlp/models/deberta_v3/deberta_v3_masked_lm_preprocessor
should,"If
  passing a list, each element of the list should be a single word
  piece token string.",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_tokenizer
should,"If passing a filename, the file should be a
  plain text file containing a single word piece token per line.",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_tokenizer
must,"Must be one of ""distil_bert_base_en_uncased"", ""distil_bert_base_en"", ""distil_bert_base_multi"".",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_tokenizer
must,"Must be one of ""distil_bert_base_en_uncased"", ""distil_bert_base_en"", ""distil_bert_base_multi"".",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_preprocessor
must,The hidden size must be divisible by the number of attention heads.,https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_backbone
note,"Note that some computations,
  such as softmax and layer normalization, will always be done at
  float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_backbone
must,"Must be one of ""distil_bert_base_en_uncased"", ""distil_bert_base_en"", ""distil_bert_base_multi"".",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_backbone
should,"If
  None, this model will not apply preprocessing, and inputs should
  be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_classifier
must,"Must be one of ""distil_bert_base_en_uncased"", ""distil_bert_base_en"", ""distil_bert_base_multi"".",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_classifier
should,"If None, this model will not apply preprocessing, and
  inputs should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_masked_lm
must,"Must be one of ""distil_bert_base_en_uncased"", ""distil_bert_base_en"", ""distil_bert_base_multi"".",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_masked_lm
should,Should always be None as the layer generates labels.,https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_masked_lm_preprocessor
should,"Should always be None as the layer
  generates label weights.",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_masked_lm_preprocessor
must,"Must be one of ""distil_bert_base_en_uncased"", ""distil_bert_base_en"", ""distil_bert_base_multi"".",https://keras.io/api/keras_nlp/models/distil_bert/distil_bert_masked_lm_preprocessor
must,"Must be one of ""gemma_2b_en"", ""gemma_instruct_2b_en"", ""gemma_7b_en"", ""gemma_instruct_7b_en"".",https://keras.io/api/keras_nlp/models/gemma/gemma_tokenizer
only,"GemmaPreprocessor expects the input to have only one segment, as Gemma is
mainly used for generation tasks.",https://keras.io/api/keras_nlp/models/gemma/gemma_preprocessor
must,"Must be one of ""gemma_2b_en"", ""gemma_instruct_2b_en"", ""gemma_7b_en"", ""gemma_instruct_7b_en"".",https://keras.io/api/keras_nlp/models/gemma/gemma_preprocessor
note,"Note that some
  computations, such as softmax and layer normalization will always
  be done a float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/gemma/gemma_backbone
must,"Must be one of ""gemma_2b_en"", ""gemma_instruct_2b_en"", ""gemma_7b_en"", ""gemma_instruct_7b_en"".",https://keras.io/api/keras_nlp/models/gemma/gemma_backbone
should,"model_parallel_dim_name: The axis name of the device mesh, where
  the weights should be partition on.",https://keras.io/api/keras_nlp/models/gemma/gemma_backbone
should,"If None, this model will not apply preprocessing, and inputs
  should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm
must,"Must be one of ""gemma_2b_en"", ""gemma_instruct_2b_en"", ""gemma_7b_en"", ""gemma_instruct_7b_en"".",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm
should,"If a preprocessor is attached to the model, inputs will be
preprocessed inside the generate() function and should match the
structure expected by the preprocessor layer (usually raw strings).",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm
should,"If a preprocessor is not attached, inputs should match the structure
expected by the backbone.",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm
should,"If a
  preprocessor is attached to the model, inputs should match
  the structure expected by the preprocessor layer.",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm
should,"If a
  preprocessor is not attached, inputs should match the
  structure expected the backbone model.",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm
should,"If preprocessor is None, inputs should be
  should be padded to the desired maximum length and this argument
  will be ignored.",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm
should,"padding_mask: A [batch_size, num_tokens] tensor indicating the
  tokens that should be preserved during generation.",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm
must,"This function must
  return a [batch_size, num_tokens, hidden_dims] tensor
  that can be passed as an input to the next layer in the model.",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm
should,"target_ids: An [batch_size, num_tokens] tensor containing the
  predicted tokens against which the loss should be computed.",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm
should,Should always be None as the layer generates labels.,https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm_preprocessor
should,"Should always be None as the layer
  generates label weights.",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm_preprocessor
must,"Must be one of ""gemma_2b_en"", ""gemma_instruct_2b_en"", ""gemma_7b_en"", ""gemma_instruct_7b_en"".",https://keras.io/api/keras_nlp/models/gemma/gemma_causal_lm_preprocessor
should,"If it is a
  string, it should be the file path to a json file.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_tokenizer
should,"If it is a string,
  it should be the file path to merge rules.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_tokenizer
should,"The merge rule file
  should have one merge rule per line.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_tokenizer
must,"Must be one of ""gpt2_base_en"", ""gpt2_medium_en"", ""gpt2_large_en"", ""gpt2_extra_large_en"", ""gpt2_base_en_cnn_dailymail"".",https://keras.io/api/keras_nlp/models/gpt2/gpt2_tokenizer
only,"GPT2Preprocessor forces the input to have only one segment, as GPT2 is
mainly used for generation tasks.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_preprocessor
must,"Must be one of ""gpt2_base_en"", ""gpt2_medium_en"", ""gpt2_large_en"", ""gpt2_extra_large_en"", ""gpt2_base_en_cnn_dailymail"".",https://keras.io/api/keras_nlp/models/gpt2/gpt2_preprocessor
must,The hidden size must be divisible by the number of attention heads.,https://keras.io/api/keras_nlp/models/gpt2/gpt2_backbone
note,"Note that some
  computations, such as softmax and layer normalization will always
  be done a float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_backbone
must,"Must be one of ""gpt2_base_en"", ""gpt2_medium_en"", ""gpt2_large_en"", ""gpt2_extra_large_en"", ""gpt2_base_en_cnn_dailymail"".",https://keras.io/api/keras_nlp/models/gpt2/gpt2_backbone
should,"If None, this model will not apply preprocessing, and inputs
  should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm
must,"Must be one of ""gpt2_base_en"", ""gpt2_medium_en"", ""gpt2_large_en"", ""gpt2_extra_large_en"", ""gpt2_base_en_cnn_dailymail"".",https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm
should,"If a preprocessor is attached to the model, inputs will be
preprocessed inside the generate() function and should match the
structure expected by the preprocessor layer (usually raw strings).",https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm
should,"If a preprocessor is not attached, inputs should match the structure
expected by the backbone.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm
should,"If a
  preprocessor is attached to the model, inputs should match
  the structure expected by the preprocessor layer.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm
should,"If a
  preprocessor is not attached, inputs should match the
  structure expected the backbone model.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm
should,"If preprocessor is None, inputs should be
  should be padded to the desired maximum length and this argument
  will be ignored.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm
should,Should always be None as the layer generates labels.,https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm_preprocessor
should,"Should always be None as the layer
  generates label weights.",https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm_preprocessor
must,"Must be one of ""gpt2_base_en"", ""gpt2_medium_en"", ""gpt2_large_en"", ""gpt2_extra_large_en"", ""gpt2_base_en_cnn_dailymail"".",https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm_preprocessor
must,"Must be one of ""f_net_base_en"", ""f_net_large_en"".",https://keras.io/api/keras_nlp/models/f_net/f_net_tokenizer
must,"Must be one of ""f_net_base_en"", ""f_net_large_en"".",https://keras.io/api/keras_nlp/models/f_net/f_net_preprocessor
note,"Note: unlike other models, FNet does not take in a ""padding_mask"" input,
the ""<pad>"" token is handled equivalently to all other tokens in the input
sequence.",https://keras.io/api/keras_nlp/models/f_net/f_net3_backbone
note,"Note that some computations,
  such as softmax and layer normalization, will always be done at
  float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/f_net/f_net3_backbone
must,"Must be one of ""f_net_base_en"", ""f_net_large_en"".",https://keras.io/api/keras_nlp/models/f_net/f_net3_backbone
should,"If
  None, this model will not apply preprocessing, and inputs should
  be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/f_net/f_net_classifier
must,"Must be one of ""f_net_base_en"", ""f_net_large_en"".",https://keras.io/api/keras_nlp/models/f_net/f_net_classifier
should,"If None, this model will not apply preprocessing, and
  inputs should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/f_net/f_net_masked_lm
must,"Must be one of ""f_net_base_en"", ""f_net_large_en"".",https://keras.io/api/keras_nlp/models/f_net/f_net_masked_lm
must,"mask_token_rate must be
  between 0 and 1 which indicates how often the mask_token is
  substituted for tokens selected for masking.",https://keras.io/api/keras_nlp/models/f_net/f_net_masked_lm_preprocessor
must,"random_token_rate must be
  between 0 and 1 which indicates how often a random token is
  substituted for tokens selected for masking.",https://keras.io/api/keras_nlp/models/f_net/f_net_masked_lm_preprocessor
note,"Note: mask_token_rate + random_token_rate <= 1,  and for
  (1 - mask_token_rate - random_token_rate), the token will not be
  changed.",https://keras.io/api/keras_nlp/models/f_net/f_net_masked_lm_preprocessor
must,"Must be one of ""f_net_base_en"", ""f_net_large_en"".",https://keras.io/api/keras_nlp/models/f_net/f_net_masked_lm_preprocessor
must,"Must be one of ""mistral_7b_en"", ""mistral_instruct_7b_en"".",https://keras.io/api/keras_nlp/models/mistral/mistral_tokenizer
must,"Must be one of ""mistral_7b_en"", ""mistral_instruct_7b_en"".",https://keras.io/api/keras_nlp/models/mistral/mistral_preprocessor
only,"Only sliding_window number of tokens
  are saved in the cache and used to generate the next token.",https://keras.io/api/keras_nlp/models/mistral/mistral_backbone
note,"Note that some computations,
  such as softmax and layer normalization, will always be done at
  float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/mistral/mistral_backbone
must,"Must be one of ""mistral_7b_en"", ""mistral_instruct_7b_en"".",https://keras.io/api/keras_nlp/models/mistral/mistral_backbone
should,"If None, this model will not apply preprocessing, and inputs
  should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/mistral/mistral_causal_lm
must,"Must be one of ""mistral_7b_en"", ""mistral_instruct_7b_en"".",https://keras.io/api/keras_nlp/models/mistral/mistral_causal_lm
should,"If a preprocessor is attached to the model, inputs will be
preprocessed inside the generate() function and should match the
structure expected by the preprocessor layer (usually raw strings).",https://keras.io/api/keras_nlp/models/mistral/mistral_causal_lm
should,"If a preprocessor is not attached, inputs should match the structure
expected by the backbone.",https://keras.io/api/keras_nlp/models/mistral/mistral_causal_lm
should,"If a
  preprocessor is attached to the model, inputs should match
  the structure expected by the preprocessor layer.",https://keras.io/api/keras_nlp/models/mistral/mistral_causal_lm
should,"If a
  preprocessor is not attached, inputs should match the
  structure expected the backbone model.",https://keras.io/api/keras_nlp/models/mistral/mistral_causal_lm
should,"If preprocessor is None, inputs should be
  should be padded to the desired maximum length and this argument
  will be ignored.",https://keras.io/api/keras_nlp/models/mistral/mistral_causal_lm
should,Should always be None as the layer generates labels.,https://keras.io/api/keras_nlp/models/mistral/mistral_causal_lm_preprocessor
should,"Should always be None as the layer
  generates label weights.",https://keras.io/api/keras_nlp/models/mistral/mistral_causal_lm_preprocessor
must,"Must be one of ""mistral_7b_en"", ""mistral_instruct_7b_en"".",https://keras.io/api/keras_nlp/models/mistral/mistral_causal_lm_preprocessor
should,"If it is a
  string, it should be the file path to a json file.",https://keras.io/api/keras_nlp/models/opt/opt_tokenizer
should,"If it is a string,
  it should be the file path to merge rules.",https://keras.io/api/keras_nlp/models/opt/opt_tokenizer
should,"The merge rule file
  should have one merge rule per line.",https://keras.io/api/keras_nlp/models/opt/opt_tokenizer
must,"Must be one of ""opt_125m_en"", ""opt_1.",https://keras.io/api/keras_nlp/models/opt/opt_tokenizer
only,"OPTPreprocessor forces the input to have only one segment, as OPT is
mainly used for generation tasks.",https://keras.io/api/keras_nlp/models/opt/opt_preprocessor
must,"Must be one of ""opt_125m_en"", ""opt_1.",https://keras.io/api/keras_nlp/models/opt/opt_preprocessor
must,The hidden size must be divisible by the number of attention heads.,https://keras.io/api/keras_nlp/models/opt/opt_backbone
note,"Note that some computations,
  such as softmax and layer normalization, will always be done at
  float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/opt/opt_backbone
must,"Must be one of ""opt_125m_en"", ""opt_1.",https://keras.io/api/keras_nlp/models/opt/opt_backbone
should,"If None, this model will not apply preprocessing, and inputs
  should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/opt/opt_causal_lm
must,"Must be one of ""opt_125m_en"", ""opt_1.",https://keras.io/api/keras_nlp/models/opt/opt_causal_lm
should,"If a preprocessor is attached to the model, inputs will be
preprocessed inside the generate() function and should match the
structure expected by the preprocessor layer (usually raw strings).",https://keras.io/api/keras_nlp/models/opt/opt_causal_lm
should,"If a preprocessor is not attached, inputs should match the structure
expected by the backbone.",https://keras.io/api/keras_nlp/models/opt/opt_causal_lm
should,"If a
  preprocessor is attached to the model, inputs should match
  the structure expected by the preprocessor layer.",https://keras.io/api/keras_nlp/models/opt/opt_causal_lm
should,"If a
  preprocessor is not attached, inputs should match the
  structure expected the backbone model.",https://keras.io/api/keras_nlp/models/opt/opt_causal_lm
should,"If preprocessor is None, inputs should be
  should be padded to the desired maximum length and this argument
  will be ignored.",https://keras.io/api/keras_nlp/models/opt/opt_causal_lm
should,Should always be None as the layer generates labels.,https://keras.io/api/keras_nlp/models/opt/opt_causal_lm_preprocessor
should,"Should always be None as the layer
  generates label weights.",https://keras.io/api/keras_nlp/models/opt/opt_causal_lm_preprocessor
only,If False only features will be returned.,https://keras.io/api/keras_nlp/models/opt/opt_causal_lm_preprocessor
must,"Must be one of ""opt_125m_en"", ""opt_1.",https://keras.io/api/keras_nlp/models/opt/opt_causal_lm_preprocessor
should,the file should have one merge rule per line.,https://keras.io/api/keras_nlp/models/roberta/roberta_tokenizer
must,"Must be one of ""roberta_base_en"", ""roberta_large_en"".",https://keras.io/api/keras_nlp/models/roberta/roberta_tokenizer
must,"Must be one of ""roberta_base_en"", ""roberta_large_en"".",https://keras.io/api/keras_nlp/models/roberta/roberta_preprocessor
must,The hidden size must be divisible by the number of attention heads.,https://keras.io/api/keras_nlp/models/roberta/roberta_backbone
must,"The sequence length of the input must be less than
  max_sequence_length default value.",https://keras.io/api/keras_nlp/models/roberta/roberta_backbone
note,"Note that some computations,
  such as softmax and layer normalization, will always be done at
  float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/roberta/roberta_backbone
must,"Must be one of ""roberta_base_en"", ""roberta_large_en"".",https://keras.io/api/keras_nlp/models/roberta/roberta_backbone
should,"If
  None, this model will not apply preprocessing, and inputs should
  be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/roberta/roberta_classifier
must,"Must be one of ""roberta_base_en"", ""roberta_large_en"".",https://keras.io/api/keras_nlp/models/roberta/roberta_classifier
should,"If None, this model will not apply preprocessing, and
  inputs should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/roberta/roberta_masked_lm
must,"Must be one of ""roberta_base_en"", ""roberta_large_en"".",https://keras.io/api/keras_nlp/models/roberta/roberta_masked_lm
should,Should always be None as the layer generates labels.,https://keras.io/api/keras_nlp/models/roberta/roberta_masked_lm_preprocessor
should,"Should always be None as the layer
  generates label weights.",https://keras.io/api/keras_nlp/models/roberta/roberta_masked_lm_preprocessor
must,"Must be one of ""roberta_base_en"", ""roberta_large_en"".",https://keras.io/api/keras_nlp/models/roberta/roberta_masked_lm_preprocessor
note,"Note: If you are providing your own custom SentencePiece model, the original
fairseq implementation of XLM-RoBERTa re-maps some token indices from the
underlying sentencepiece output.",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_tokenizer
must,"Must be one of ""xlm_roberta_base_multi"", ""xlm_roberta_large_multi"".",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_tokenizer
must,"Must be one of ""xlm_roberta_base_multi"", ""xlm_roberta_large_multi"".",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_preprocessor
must,The hidden size must be divisible by the number of attention heads.,https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_backbone
must,"The sequence length of the input must be less than
  max_sequence_length default value.",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_backbone
note,"Note that some computations,
  such as softmax and layer normalization, will always be done at
  float32 precision regardless of dtype.",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_backbone
must,"Must be one of ""xlm_roberta_base_multi"", ""xlm_roberta_large_multi"".",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_backbone
should,"If
  None, this model will not apply preprocessing, and inputs should
  be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_classifier
must,"Must be one of ""xlm_roberta_base_multi"", ""xlm_roberta_large_multi"".",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_classifier
should,"If None, this model will not apply preprocessing, and
  inputs should be preprocessed before calling the model.",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_masked_lm
must,"Must be one of ""xlm_roberta_base_multi"", ""xlm_roberta_large_multi"".",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_masked_lm
should,Should always be None as the layer generates labels.,https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_masked_lm_preprocessor
should,"Should always be None as the layer
  generates label weights.",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_masked_lm_preprocessor
must,"Must be one of ""xlm_roberta_base_multi"", ""xlm_roberta_large_multi"".",https://keras.io/api/keras_nlp/models/xlm_roberta/xlm_roberta_masked_lm_preprocessor
must,Must be positive.,https://keras.io/api/optimizers/learning_rate_schedules/exponential_decay/
should,"It should have one more
  element than boundaries, and all elements should have the same
  type.",https://keras.io/api/optimizers/learning_rate_schedules/piecewise_constant_decay/
only,"It is commonly observed that a monotonically decreasing learning rate, whose
degree of change is carefully chosen, results in a better performing model.",https://keras.io/api/optimizers/learning_rate_schedules/polynomial_decay/
must,Must be positive.,https://keras.io/api/optimizers/learning_rate_schedules/polynomial_decay/
should,"cycle: A boolean, whether it should cycle beyond decay_steps.",https://keras.io/api/optimizers/learning_rate_schedules/polynomial_decay/
\b([\w]+\(.*?\)).*?\bbefore.*?\b([\w]+\(.*?\)),"Also, note that for the
inverse to work, you must have already set the forward layer vocabulary
either directly or via adapt() before calling get_vocabulary().",https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup
